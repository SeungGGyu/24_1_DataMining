{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\qls05\\OneDrive\\바탕 화면\\df.csv\", encoding = 'cp949')\n",
    "\n",
    "df['preprocessed_송출내용'] = df['preprocessed_송출내용'].fillna('')\n",
    "texts = df['preprocessed_송출내용']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주어진 df ->  tf-idf 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=30)\n",
    "vectored_df = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_df = vectored_df.todense() #vectored_df는 희소행렬이기 때문에 dense 형태로 전환.\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "df_tfidf = pd.DataFrame(dense_df, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5608, 30) y_train shape: (5608,)\n",
      "X_valid shape: (1870, 30) y_valid shape: (1870,)\n",
      "X_test shape: (1870, 30) y_test shape: (1870,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_tfidf\n",
    "y = df['label']\n",
    "\n",
    "# train : val : test = 6 : 2 : 2\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape, \"y_valid shape:\", y_valid.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid score: 0.696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_valid_hat = dt.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77       152\n",
      "           1       0.55      0.72      0.62       162\n",
      "           2       0.65      0.40      0.50        89\n",
      "           3       0.58      0.27      0.37        51\n",
      "           4       0.61      0.71      0.66       607\n",
      "           5       0.80      0.85      0.82       464\n",
      "           6       0.79      0.84      0.81       194\n",
      "           7       0.80      0.29      0.43       151\n",
      "\n",
      "    accuracy                           0.70      1870\n",
      "   macro avg       0.71      0.60      0.62      1870\n",
      "weighted avg       0.71      0.70      0.69      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(metrics.classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparmeter 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "302 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "238 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83844448 0.83630607 0.83808892\n",
      " 0.83719734 0.83933765 0.83791035 0.83826797 0.83862384 0.83987289\n",
      " 0.83345307 0.83648401 0.83523671 0.83826797 0.835771   0.83595036\n",
      " 0.83559322 0.83541465 0.83487957 0.8316699  0.8286369  0.82952848\n",
      " 0.8291734  0.8288161  0.82881531 0.82596262 0.82952928 0.83077816\n",
      " 0.83648385 0.83719718 0.83594973 0.83773162 0.83951558 0.83898051\n",
      " 0.83969368 0.84005098 0.84058558 0.83577131 0.83612877 0.83684163\n",
      " 0.83559322 0.8370194  0.83737639 0.83577147 0.8361275  0.83398815\n",
      " 0.83024388 0.82935118 0.82828039 0.82774643 0.83131292 0.82774611\n",
      " 0.83184768 0.82756738 0.82881563        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.82970801 0.82863912 0.82899563 0.82649929 0.82774786 0.82846023\n",
      " 0.82667818 0.82596421 0.8250739  0.82436057 0.82293375 0.82632056\n",
      " 0.82525152 0.82435978 0.82329042 0.82204169 0.82400295 0.82168502\n",
      " 0.81758329 0.81972345 0.82097169 0.8197236  0.8207928  0.81776091\n",
      " 0.81740552 0.8209709  0.81865329 0.82899452 0.82935213 0.8291742\n",
      " 0.82685564 0.82560691 0.82774754 0.82382502 0.82453739 0.82507247\n",
      " 0.82311264 0.82435898 0.82578707 0.82275407 0.82364645 0.82328978\n",
      " 0.82328978 0.82257597 0.82186185 0.82079312 0.81508632 0.81669267\n",
      " 0.81704758 0.81669251 0.81936583 0.81615616 0.81776139 0.8154441\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83470132 0.83862368 0.83684131\n",
      " 0.83898082 0.83791162 0.83737591 0.83844607 0.84005082 0.83933765\n",
      " 0.83434449 0.8352364  0.83630607 0.83470148 0.83594941 0.83505798\n",
      " 0.83470116 0.83345291 0.83256165 0.82649706 0.83131276 0.8284588\n",
      " 0.8270323  0.82845864 0.8288161  0.82917213 0.8289942  0.82863785\n",
      " 0.83612718 0.83737591 0.83773289 0.83541433 0.84022907 0.84005098\n",
      " 0.84005034 0.83951654 0.8405859  0.8354156  0.83719829 0.8375548\n",
      " 0.83434513 0.83612766 0.83612814 0.83381037 0.83345275 0.83291879\n",
      " 0.82917197 0.82828134 0.82899467 0.82988546 0.82899452 0.82917277\n",
      " 0.82917245 0.82988594 0.82631865        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83577131 0.83541449 0.83773178 0.83791019 0.83630639 0.83898035\n",
      " 0.83684115 0.83826797 0.83898098 0.83559338 0.83737671 0.83791162\n",
      " 0.83666306 0.83577147 0.83594989 0.83452418 0.83416656 0.83452338\n",
      " 0.8277469  0.82935086 0.82970785 0.82970801 0.82810182 0.8284588\n",
      " 0.82988515 0.82952864 0.83059959 0.83648449 0.83773289 0.83737575\n",
      " 0.83773146 0.8391594  0.8396932  0.83951606 0.83880289 0.83933797\n",
      " 0.83755464 0.83808972 0.83666306 0.83559243 0.83666306 0.83755416\n",
      " 0.83487973 0.83505862 0.83309688 0.83113498 0.82828103 0.82863865\n",
      " 0.82792468 0.82881563 0.82667611 0.82738944 0.8288161  0.82792388]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best score: 0.8405858978089654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.903\n",
      "valid score: 0.829\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth= 20, max_features= 'log2', min_samples_leaf= 1,\n",
    "                            min_samples_split= 10, n_estimators= 300).fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = rf.predict(X_train)\n",
    "y_valid_hat =rf.predict(X_valid)\n",
    "        \n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       152\n",
      "           1       0.71      0.72      0.72       162\n",
      "           2       0.72      0.55      0.62        89\n",
      "           3       0.74      0.49      0.59        51\n",
      "           4       0.77      0.87      0.82       607\n",
      "           5       0.97      0.92      0.94       464\n",
      "           6       0.79      0.87      0.83       194\n",
      "           7       0.88      0.70      0.78       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.81      0.75      0.78      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_valid, y_valid_hat))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
