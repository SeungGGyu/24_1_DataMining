{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. data 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 최종적으로 cluster된 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\qls05\\OneDrive\\바탕 화면\\df.csv\", encoding = 'cp949') \n",
    "#000.ipynb로부터 나온 파일임 github 링크까지 첨부하면 좋을듯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 불러온 df ->  tf-idf 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts = df['preprocessed_송출내용'].fillna('')\n",
    "vectorizer = TfidfVectorizer(max_features=30)\n",
    "vectored_df = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_df = vectored_df.todense() #vectored_df는 희소행렬이기 때문에 dense 형태로 전환.\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "df_tfidf = pd.DataFrame(dense_df, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5608, 30) y_train shape: (5608,)\n",
      "X_valid shape: (1870, 30) y_valid shape: (1870,)\n",
      "X_test shape: (1870, 30) y_test shape: (1870,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_tfidf\n",
    "y = df['label']\n",
    "\n",
    "# train : val : test = 6 : 2 : 2\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape, \"y_valid shape:\", y_valid.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) data scaling (model에 따라 scaled 된 data가 필요한 경우가 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 모델 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.863\n",
      "valid score: 0.814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = svc.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = svc.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) svc 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for문으로 탐색.** <br/>\n",
    "**1-1) C, gamma 조절**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.810093</td>\n",
       "      <td>0.783957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.759094</td>\n",
       "      <td>0.734225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.596113</td>\n",
       "      <td>0.572727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.895506</td>\n",
       "      <td>0.824064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.748039</td>\n",
       "      <td>0.724064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.603067</td>\n",
       "      <td>0.579144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.921362</td>\n",
       "      <td>0.829947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.873930</td>\n",
       "      <td>0.815508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.807061</td>\n",
       "      <td>0.778610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.747682</td>\n",
       "      <td>0.720321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.922611</td>\n",
       "      <td>0.829412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.902817</td>\n",
       "      <td>0.817112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.827568</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.787268</td>\n",
       "      <td>0.758289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C   gamma  train_accuracy  valid_accuracy\n",
       "0    0.1  0.1000        0.810093        0.783957\n",
       "1    0.1  0.0100        0.759094        0.734225\n",
       "2    0.1  0.0010        0.596113        0.572727\n",
       "3    0.1  0.0001        0.324358        0.324599\n",
       "4    1.0  0.1000        0.895506        0.824064\n",
       "5    1.0  0.0100        0.826498        0.788235\n",
       "6    1.0  0.0010        0.748039        0.724064\n",
       "7    1.0  0.0001        0.603067        0.579144\n",
       "8   10.0  0.1000        0.921362        0.829947\n",
       "9   10.0  0.0100        0.873930        0.815508\n",
       "10  10.0  0.0010        0.807061        0.778610\n",
       "11  10.0  0.0001        0.747682        0.720321\n",
       "12  50.0  0.1000        0.922611        0.829412\n",
       "13  50.0  0.0100        0.902817        0.817112\n",
       "14  50.0  0.0010        0.827568        0.788235\n",
       "15  50.0  0.0001        0.787268        0.758289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_settings = [0.1, 1, 10, 50]\n",
    "gamma_settings = [0.1, 0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for C in C_settings:\n",
    "    for gamma in gamma_settings:\n",
    "        svc = SVC(C=C, gamma=gamma, random_state=20).fit(X_train_scaled, y_train) #C, gamma 조정\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'C': C,\n",
    "                        'gamma': gamma,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2) kernel 조절**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.808131</td>\n",
       "      <td>0.770588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.864836</td>\n",
       "      <td>0.813904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.882668</td>\n",
       "      <td>0.817647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>0.616043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kernel  train_accuracy  valid_accuracy\n",
       "0   linear        0.808131        0.770588\n",
       "1      rbf        0.864836        0.813904\n",
       "2     poly        0.882668        0.817647\n",
       "3  sigmoid        0.626070        0.616043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "        svc = SVC(kernel=kernel, random_state=20).fit(X_train_scaled, y_train) #kernel 조정\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'kernel': kernel,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-3) kernel = poly로 정하고 C랑 gamma 다시 튜닝**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.901213</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.918688</td>\n",
       "      <td>0.826738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.729494</td>\n",
       "      <td>0.711765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.921719</td>\n",
       "      <td>0.830481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.846291</td>\n",
       "      <td>0.798396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.922432</td>\n",
       "      <td>0.830481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.817112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C   gamma  train_accuracy  valid_accuracy\n",
       "0    0.1  0.1000        0.901213        0.818182\n",
       "1    0.1  0.0100        0.324358        0.324599\n",
       "2    0.1  0.0010        0.324358        0.324599\n",
       "3    0.1  0.0001        0.324358        0.324599\n",
       "4    1.0  0.1000        0.918688        0.826738\n",
       "5    1.0  0.0100        0.729494        0.711765\n",
       "6    1.0  0.0010        0.324358        0.324599\n",
       "7    1.0  0.0001        0.324358        0.324599\n",
       "8   10.0  0.1000        0.921719        0.830481\n",
       "9   10.0  0.0100        0.846291        0.798396\n",
       "10  10.0  0.0010        0.324358        0.324599\n",
       "11  10.0  0.0001        0.324358        0.324599\n",
       "12  50.0  0.1000        0.922432        0.830481\n",
       "13  50.0  0.0100        0.890157        0.817112\n",
       "14  50.0  0.0010        0.324358        0.324599\n",
       "15  50.0  0.0001        0.324358        0.324599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_settings = [0.1, 1, 10, 50]\n",
    "gamma_settings = [0.1, 0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for C in C_settings:\n",
    "    for gamma in gamma_settings:\n",
    "        svc = SVC(C=C, gamma=gamma, kernel='poly', random_state=20).fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'C': C,\n",
    "                        'gamma': gamma,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적 hyperparameter:  kernel = poly, C = 50, gamma=0.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 SVC model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.922\n",
      "valid score: 0.830\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_svc = SVC(kernel='poly', C=50, gamma=0.1).fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_svc.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_svc.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       152\n",
      "           1       0.67      0.73      0.70       162\n",
      "           2       0.58      0.64      0.61        89\n",
      "           3       0.62      0.49      0.55        51\n",
      "           4       0.83      0.81      0.82       607\n",
      "           5       0.95      0.95      0.95       464\n",
      "           6       0.76      0.84      0.80       194\n",
      "           7       0.84      0.78      0.81       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.77      0.77      0.77      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 나이브베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.683\n",
      "valid score: 0.660\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = nb.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = nb.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) naive baise 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이후 gird search으로 탐색**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.01, 'fit_prior': True}\n",
      "Best score: 0.6813487533249596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    'fit_prior': [True, False]\n",
    "    }\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 Naive Baise model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.689\n",
      "valid score: 0.672\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_nb = MultinomialNB(alpha=grid_search.best_params_['alpha'], fit_prior=grid_search.best_params_['fit_prior'])\n",
    "best_nb.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_nb.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_nb.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       152\n",
      "           1       0.68      0.57      0.62       162\n",
      "           2       0.70      0.08      0.14        89\n",
      "           3       0.00      0.00      0.00        51\n",
      "           4       0.58      0.68      0.62       607\n",
      "           5       0.74      0.90      0.81       464\n",
      "           6       0.65      0.87      0.74       194\n",
      "           7       0.76      0.17      0.28       151\n",
      "\n",
      "    accuracy                           0.67      1870\n",
      "   macro avg       0.63      0.52      0.51      1870\n",
      "weighted avg       0.66      0.67      0.64      1870\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#상세보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.923\n",
      "valid score: 0.830\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = rf.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) random forest 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "324 fits failed out of a total of 972.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "139 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "185 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83505797 0.83416633 0.83791126\n",
      " 0.83256128 0.83648428 0.83612787 0.83505769 0.83612692 0.8361274\n",
      " 0.83220392 0.83452169 0.83256071 0.83113431 0.83113364 0.83327363\n",
      " 0.83113383 0.82988625 0.83095548 0.8213259  0.82435802 0.82417929\n",
      " 0.82614093 0.82346627 0.82560588 0.82578423 0.82560569 0.82435754\n",
      " 0.83541496 0.83737574 0.83684098 0.83541467 0.83773215 0.83791098\n",
      " 0.8375539  0.83612721 0.83523556 0.83202595 0.83345245 0.83273925\n",
      " 0.83309576 0.83273858 0.83166907 0.83113373 0.82970771 0.82988587\n",
      " 0.82382269 0.82631956 0.82346656 0.82507093 0.82542754 0.82578414\n",
      " 0.82221774 0.82489249 0.82489249        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.82417919 0.82649801 0.82524966 0.82346666 0.82507065 0.82489278\n",
      " 0.82061384 0.82328812 0.82275326 0.82168327 0.82257444 0.8229318\n",
      " 0.82186057 0.82025667 0.82168308 0.82097006 0.81633396 0.82168279\n",
      " 0.81758125 0.81579862 0.81668999 0.81365825 0.81490745 0.81455028\n",
      " 0.81651183 0.81561999 0.81740347 0.82489335 0.82667607 0.82400142\n",
      " 0.82275259 0.82667598 0.82417995 0.81954423 0.82203996 0.82221784\n",
      " 0.81954337 0.8216826  0.82293171 0.82043425 0.82221803 0.82221803\n",
      " 0.81847385 0.82025667 0.82096968 0.80973563 0.81455047 0.81401552\n",
      " 0.80991408 0.81330175 0.81597669 0.81312321 0.81419387 0.81579805\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83505807 0.83737584 0.83755466\n",
      " 0.83701876 0.83844574 0.83719739 0.83256081 0.83559178 0.83559226\n",
      " 0.83256052 0.83113421 0.8325609  0.83059917 0.83291665 0.8332742\n",
      " 0.82881597 0.83131199 0.82863752 0.82542754 0.82507103 0.82560598\n",
      " 0.82400122 0.82471405 0.82435764 0.82524909 0.82417967 0.82453617\n",
      " 0.83684098 0.8350575  0.83773282 0.83684079 0.83933691 0.83791069\n",
      " 0.83577051 0.83648409 0.83648409 0.83220382 0.83309557 0.83202509\n",
      " 0.83220392 0.83059907 0.83220382 0.83095558 0.83113373 0.83095567\n",
      " 0.82257386 0.82489259 0.82275279 0.82257482 0.82435754 0.82542763\n",
      " 0.82328783 0.8248923  0.82560541        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83701962 0.83523642 0.83434429 0.83737593 0.8382672  0.83701904\n",
      " 0.83523556 0.83541391 0.83701857 0.83238236 0.83273887 0.83220382\n",
      " 0.83256071 0.83202538 0.83327411 0.83042015 0.82881558 0.83238198\n",
      " 0.82542696 0.82382269 0.8241791  0.8234658  0.82400122 0.82721083\n",
      " 0.82275307 0.82435764 0.82596287 0.83487924 0.83808923 0.83684098\n",
      " 0.83612711 0.83755428 0.83880215 0.8343441  0.83594914 0.83701895\n",
      " 0.83345284 0.83380896 0.83238189 0.83184646 0.83166868 0.83273897\n",
      " 0.83095558 0.83024237 0.83095586 0.82310939 0.82346608 0.82489192\n",
      " 0.82382316 0.82578366 0.82435754 0.82382259 0.82168288 0.82417929]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best score: 0.8393369060256038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 RandomForest model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.917\n",
      "valid score: 0.832\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    max_features=grid_search.best_params_['max_features'],\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_rf.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       152\n",
      "           1       0.71      0.73      0.72       162\n",
      "           2       0.72      0.56      0.63        89\n",
      "           3       0.68      0.49      0.57        51\n",
      "           4       0.77      0.86      0.81       607\n",
      "           5       0.97      0.92      0.95       464\n",
      "           6       0.79      0.86      0.82       194\n",
      "           7       0.90      0.72      0.80       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.81      0.76      0.78      1870\n",
      "weighted avg       0.84      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\qls05\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.922\n",
      "valid score: 0.827\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = xg.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = xg.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) XGBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best score: 0.8375539933372055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xg= xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xg, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 XGBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.910\n",
      "valid score: 0.824\n"
     ]
    }
   ],
   "source": [
    "#모델 적용                                                                                                                                                                                                                        4                                                   \n",
    "best_xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    subsample=grid_search.best_params_['subsample'],\n",
    "    colsample_bytree=grid_search.best_params_['colsample_bytree'])\n",
    "best_xg.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_xg.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_xg.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       152\n",
      "           1       0.71      0.73      0.72       162\n",
      "           2       0.70      0.56      0.62        89\n",
      "           3       0.69      0.47      0.56        51\n",
      "           4       0.78      0.83      0.81       607\n",
      "           5       0.95      0.92      0.94       464\n",
      "           6       0.77      0.86      0.81       194\n",
      "           7       0.82      0.74      0.78       151\n",
      "\n",
      "    accuracy                           0.82      1870\n",
      "   macro avg       0.79      0.75      0.77      1870\n",
      "weighted avg       0.82      0.82      0.82      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    #상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\qls05\\anaconda3\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2020.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (20.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (6.3.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.897\n",
      "valid score: 0.822\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "cat = CatBoostClassifier(loss_function='MultiClass', verbose=0)\n",
    "cat.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
    "\n",
    "y_train_hat = cat.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = cat.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) CatBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05}\n",
      "Best score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'iterations': [500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "cat = CatBoostClassifier(early_stopping_rounds=50, verbose=False)\n",
    "grid_search = GridSearchCV(cat, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 CatBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.896\n",
      "valid score: 0.828\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_cat = CatBoostClassifier(verbose=0,\n",
    "    iterations=grid_search.best_params_['iterations'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    depth=grid_search.best_params_['depth'],\n",
    "    l2_leaf_reg=grid_search.best_params_['l2_leaf_reg'])\n",
    "best_cat.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_cat.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_cat.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       152\n",
      "           1       0.70      0.73      0.72       162\n",
      "           2       0.74      0.57      0.65        89\n",
      "           3       0.63      0.47      0.54        51\n",
      "           4       0.78      0.85      0.81       607\n",
      "           5       0.94      0.92      0.93       464\n",
      "           6       0.79      0.86      0.82       194\n",
      "           7       0.88      0.74      0.80       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.80      0.75      0.77      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(metrics.classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. 최종 모델 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각모델의 valid score<br/><br/>\n",
    "\n",
    "svc = 0.830<br/>\n",
    "나이브베이즈 = 0.672<br/>\n",
    "랜덤포레스트 = 0.830<br/>\n",
    "XGBoost = 0.824<br/>\n",
    "catBoost = 0.828 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**나이브 베이즈를 제외한 4가지 모델의 성능이0.01정도의 차이를 보이므로 cross validuation으로 재평가 (fold=5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train: test = 8: 2로 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc model cross validation score: 0.762\n",
      "rf model cross validation score: 0.838\n",
      "XGboost model cross validation score: 0.838\n",
      "CatBoost model cross validation score: 0.841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#모델별 5개의 fold로 교차검증\n",
    "svc_cv_score = cross_val_score(best_svc, X_train, y_train, cv=5) \n",
    "print(\"svc model cross validation score: %.3f\" %svc_cv_score.mean())\n",
    "\n",
    "rf_cv_score = cross_val_score(best_rf, X_train, y_train, cv=5) \n",
    "print(\"rf model cross validation score: %.3f\" %rf_cv_score.mean())\n",
    "\n",
    "xg_cv_score = cross_val_score(best_xg, X_train, y_train, cv=5) \n",
    "print(\"XGboost model cross validation score: %.3f\" %xg_cv_score.mean())\n",
    "\n",
    "cat_cv_score = cross_val_score(best_cat, X_train, y_train, cv=5) \n",
    "print(\"CatBoost model cross validation score: %.3f\" %cat_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05]일때의 catBoost 모델이 성능이 가장 높은 것을 알 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model 생성 및 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9208144\ttotal: 1.23s\tremaining: 10m 13s\n",
      "1:\tlearn: 1.7957177\ttotal: 2.51s\tremaining: 10m 24s\n",
      "2:\tlearn: 1.6882446\ttotal: 3.68s\tremaining: 10m 9s\n",
      "3:\tlearn: 1.5955640\ttotal: 4.84s\tremaining: 10m\n",
      "4:\tlearn: 1.5209007\ttotal: 6.09s\tremaining: 10m 3s\n",
      "5:\tlearn: 1.4512460\ttotal: 7.44s\tremaining: 10m 12s\n",
      "6:\tlearn: 1.3906001\ttotal: 8.63s\tremaining: 10m 7s\n",
      "7:\tlearn: 1.3359669\ttotal: 9.92s\tremaining: 10m 9s\n",
      "8:\tlearn: 1.2836768\ttotal: 11.2s\tremaining: 10m 9s\n",
      "9:\tlearn: 1.2387172\ttotal: 12.5s\tremaining: 10m 14s\n",
      "10:\tlearn: 1.1978746\ttotal: 14.1s\tremaining: 10m 28s\n",
      "11:\tlearn: 1.1603640\ttotal: 15.5s\tremaining: 10m 28s\n",
      "12:\tlearn: 1.1250483\ttotal: 16.9s\tremaining: 10m 32s\n",
      "13:\tlearn: 1.0946970\ttotal: 18.1s\tremaining: 10m 26s\n",
      "14:\tlearn: 1.0640530\ttotal: 19.2s\tremaining: 10m 21s\n",
      "15:\tlearn: 1.0366113\ttotal: 20.4s\tremaining: 10m 17s\n",
      "16:\tlearn: 1.0109435\ttotal: 21.7s\tremaining: 10m 16s\n",
      "17:\tlearn: 0.9862320\ttotal: 23s\tremaining: 10m 15s\n",
      "18:\tlearn: 0.9642834\ttotal: 24.4s\tremaining: 10m 16s\n",
      "19:\tlearn: 0.9428077\ttotal: 25.6s\tremaining: 10m 14s\n",
      "20:\tlearn: 0.9222535\ttotal: 26.9s\tremaining: 10m 13s\n",
      "21:\tlearn: 0.9031973\ttotal: 28.4s\tremaining: 10m 16s\n",
      "22:\tlearn: 0.8853491\ttotal: 29.7s\tremaining: 10m 14s\n",
      "23:\tlearn: 0.8688010\ttotal: 31s\tremaining: 10m 15s\n",
      "24:\tlearn: 0.8533446\ttotal: 32.5s\tremaining: 10m 17s\n",
      "25:\tlearn: 0.8386121\ttotal: 33.8s\tremaining: 10m 15s\n",
      "26:\tlearn: 0.8238663\ttotal: 35.3s\tremaining: 10m 18s\n",
      "27:\tlearn: 0.8102541\ttotal: 36.7s\tremaining: 10m 19s\n",
      "28:\tlearn: 0.7979564\ttotal: 38.3s\tremaining: 10m 22s\n",
      "29:\tlearn: 0.7869894\ttotal: 39.7s\tremaining: 10m 21s\n",
      "30:\tlearn: 0.7753811\ttotal: 41.2s\tremaining: 10m 22s\n",
      "31:\tlearn: 0.7645524\ttotal: 42.7s\tremaining: 10m 23s\n",
      "32:\tlearn: 0.7528671\ttotal: 44.2s\tremaining: 10m 25s\n",
      "33:\tlearn: 0.7425438\ttotal: 45.6s\tremaining: 10m 24s\n",
      "34:\tlearn: 0.7337091\ttotal: 46.9s\tremaining: 10m 22s\n",
      "35:\tlearn: 0.7245877\ttotal: 48.3s\tremaining: 10m 22s\n",
      "36:\tlearn: 0.7154140\ttotal: 49.6s\tremaining: 10m 20s\n",
      "37:\tlearn: 0.7067933\ttotal: 50.9s\tremaining: 10m 18s\n",
      "38:\tlearn: 0.6980354\ttotal: 52.4s\tremaining: 10m 19s\n",
      "39:\tlearn: 0.6907039\ttotal: 53.7s\tremaining: 10m 17s\n",
      "40:\tlearn: 0.6830034\ttotal: 55.1s\tremaining: 10m 16s\n",
      "41:\tlearn: 0.6763784\ttotal: 56.4s\tremaining: 10m 15s\n",
      "42:\tlearn: 0.6697502\ttotal: 57.8s\tremaining: 10m 14s\n",
      "43:\tlearn: 0.6631156\ttotal: 59.2s\tremaining: 10m 13s\n",
      "44:\tlearn: 0.6574339\ttotal: 1m\tremaining: 10m 11s\n",
      "45:\tlearn: 0.6517560\ttotal: 1m 1s\tremaining: 10m 9s\n",
      "46:\tlearn: 0.6452748\ttotal: 1m 3s\tremaining: 10m 7s\n",
      "47:\tlearn: 0.6405544\ttotal: 1m 4s\tremaining: 10m 7s\n",
      "48:\tlearn: 0.6361180\ttotal: 1m 5s\tremaining: 10m 7s\n",
      "49:\tlearn: 0.6313064\ttotal: 1m 7s\tremaining: 10m 7s\n",
      "50:\tlearn: 0.6267162\ttotal: 1m 8s\tremaining: 10m 6s\n",
      "51:\tlearn: 0.6213045\ttotal: 1m 10s\tremaining: 10m 6s\n",
      "52:\tlearn: 0.6169348\ttotal: 1m 11s\tremaining: 10m 6s\n",
      "53:\tlearn: 0.6132851\ttotal: 1m 13s\tremaining: 10m 4s\n",
      "54:\tlearn: 0.6092009\ttotal: 1m 14s\tremaining: 10m 3s\n",
      "55:\tlearn: 0.6051056\ttotal: 1m 15s\tremaining: 10m 1s\n",
      "56:\tlearn: 0.6007028\ttotal: 1m 17s\tremaining: 9m 59s\n",
      "57:\tlearn: 0.5970751\ttotal: 1m 18s\tremaining: 9m 59s\n",
      "58:\tlearn: 0.5934769\ttotal: 1m 20s\tremaining: 9m 59s\n",
      "59:\tlearn: 0.5900091\ttotal: 1m 21s\tremaining: 9m 57s\n",
      "60:\tlearn: 0.5866844\ttotal: 1m 22s\tremaining: 9m 56s\n",
      "61:\tlearn: 0.5835252\ttotal: 1m 24s\tremaining: 9m 54s\n",
      "62:\tlearn: 0.5801917\ttotal: 1m 25s\tremaining: 9m 54s\n",
      "63:\tlearn: 0.5765699\ttotal: 1m 27s\tremaining: 9m 53s\n",
      "64:\tlearn: 0.5737398\ttotal: 1m 28s\tremaining: 9m 52s\n",
      "65:\tlearn: 0.5712151\ttotal: 1m 29s\tremaining: 9m 51s\n",
      "66:\tlearn: 0.5682282\ttotal: 1m 31s\tremaining: 9m 51s\n",
      "67:\tlearn: 0.5656649\ttotal: 1m 32s\tremaining: 9m 50s\n",
      "68:\tlearn: 0.5619280\ttotal: 1m 34s\tremaining: 9m 48s\n",
      "69:\tlearn: 0.5589464\ttotal: 1m 35s\tremaining: 9m 46s\n",
      "70:\tlearn: 0.5558918\ttotal: 1m 36s\tremaining: 9m 44s\n",
      "71:\tlearn: 0.5531186\ttotal: 1m 37s\tremaining: 9m 42s\n",
      "72:\tlearn: 0.5505712\ttotal: 1m 39s\tremaining: 9m 41s\n",
      "73:\tlearn: 0.5484007\ttotal: 1m 40s\tremaining: 9m 40s\n",
      "74:\tlearn: 0.5462355\ttotal: 1m 42s\tremaining: 9m 39s\n",
      "75:\tlearn: 0.5443007\ttotal: 1m 44s\tremaining: 9m 41s\n",
      "76:\tlearn: 0.5421063\ttotal: 1m 45s\tremaining: 9m 40s\n",
      "77:\tlearn: 0.5399767\ttotal: 1m 47s\tremaining: 9m 38s\n",
      "78:\tlearn: 0.5375537\ttotal: 1m 48s\tremaining: 9m 37s\n",
      "79:\tlearn: 0.5352004\ttotal: 1m 49s\tremaining: 9m 36s\n",
      "80:\tlearn: 0.5333195\ttotal: 1m 51s\tremaining: 9m 35s\n",
      "81:\tlearn: 0.5311882\ttotal: 1m 52s\tremaining: 9m 34s\n",
      "82:\tlearn: 0.5284824\ttotal: 1m 54s\tremaining: 9m 33s\n",
      "83:\tlearn: 0.5266673\ttotal: 1m 55s\tremaining: 9m 33s\n",
      "84:\tlearn: 0.5250414\ttotal: 1m 57s\tremaining: 9m 32s\n",
      "85:\tlearn: 0.5235361\ttotal: 1m 58s\tremaining: 9m 31s\n",
      "86:\tlearn: 0.5217352\ttotal: 2m\tremaining: 9m 30s\n",
      "87:\tlearn: 0.5204934\ttotal: 2m 1s\tremaining: 9m 29s\n",
      "88:\tlearn: 0.5186472\ttotal: 2m 3s\tremaining: 9m 28s\n",
      "89:\tlearn: 0.5167958\ttotal: 2m 4s\tremaining: 9m 26s\n",
      "90:\tlearn: 0.5150913\ttotal: 2m 6s\tremaining: 9m 26s\n",
      "91:\tlearn: 0.5133786\ttotal: 2m 7s\tremaining: 9m 25s\n",
      "92:\tlearn: 0.5115942\ttotal: 2m 9s\tremaining: 9m 24s\n",
      "93:\tlearn: 0.5104603\ttotal: 2m 10s\tremaining: 9m 24s\n",
      "94:\tlearn: 0.5093176\ttotal: 2m 12s\tremaining: 9m 24s\n",
      "95:\tlearn: 0.5074976\ttotal: 2m 14s\tremaining: 9m 24s\n",
      "96:\tlearn: 0.5059590\ttotal: 2m 15s\tremaining: 9m 24s\n",
      "97:\tlearn: 0.5046165\ttotal: 2m 17s\tremaining: 9m 22s\n",
      "98:\tlearn: 0.5032332\ttotal: 2m 18s\tremaining: 9m 21s\n",
      "99:\tlearn: 0.5019497\ttotal: 2m 19s\tremaining: 9m 19s\n",
      "100:\tlearn: 0.5006433\ttotal: 2m 21s\tremaining: 9m 18s\n",
      "101:\tlearn: 0.4988347\ttotal: 2m 22s\tremaining: 9m 17s\n",
      "102:\tlearn: 0.4976184\ttotal: 2m 24s\tremaining: 9m 18s\n",
      "103:\tlearn: 0.4957883\ttotal: 2m 26s\tremaining: 9m 18s\n",
      "104:\tlearn: 0.4941094\ttotal: 2m 28s\tremaining: 9m 17s\n",
      "105:\tlearn: 0.4930065\ttotal: 2m 29s\tremaining: 9m 17s\n",
      "106:\tlearn: 0.4918778\ttotal: 2m 31s\tremaining: 9m 16s\n",
      "107:\tlearn: 0.4910350\ttotal: 2m 33s\tremaining: 9m 16s\n",
      "108:\tlearn: 0.4899848\ttotal: 2m 35s\tremaining: 9m 16s\n",
      "109:\tlearn: 0.4889531\ttotal: 2m 36s\tremaining: 9m 15s\n",
      "110:\tlearn: 0.4876378\ttotal: 2m 38s\tremaining: 9m 14s\n",
      "111:\tlearn: 0.4864494\ttotal: 2m 40s\tremaining: 9m 14s\n",
      "112:\tlearn: 0.4853033\ttotal: 2m 41s\tremaining: 9m 12s\n",
      "113:\tlearn: 0.4842766\ttotal: 2m 42s\tremaining: 9m 10s\n",
      "114:\tlearn: 0.4831619\ttotal: 2m 43s\tremaining: 9m 8s\n",
      "115:\tlearn: 0.4819001\ttotal: 2m 45s\tremaining: 9m 7s\n",
      "116:\tlearn: 0.4810731\ttotal: 2m 46s\tremaining: 9m 5s\n",
      "117:\tlearn: 0.4803124\ttotal: 2m 47s\tremaining: 9m 3s\n",
      "118:\tlearn: 0.4789129\ttotal: 2m 49s\tremaining: 9m 1s\n",
      "119:\tlearn: 0.4780596\ttotal: 2m 50s\tremaining: 8m 59s\n",
      "120:\tlearn: 0.4773592\ttotal: 2m 51s\tremaining: 8m 57s\n",
      "121:\tlearn: 0.4764234\ttotal: 2m 53s\tremaining: 8m 56s\n",
      "122:\tlearn: 0.4749934\ttotal: 2m 54s\tremaining: 8m 54s\n",
      "123:\tlearn: 0.4744517\ttotal: 2m 55s\tremaining: 8m 52s\n",
      "124:\tlearn: 0.4736094\ttotal: 2m 57s\tremaining: 8m 53s\n",
      "125:\tlearn: 0.4727047\ttotal: 2m 59s\tremaining: 8m 52s\n",
      "126:\tlearn: 0.4718949\ttotal: 3m 1s\tremaining: 8m 51s\n",
      "127:\tlearn: 0.4709219\ttotal: 3m 2s\tremaining: 8m 51s\n",
      "128:\tlearn: 0.4701690\ttotal: 3m 4s\tremaining: 8m 50s\n",
      "129:\tlearn: 0.4692568\ttotal: 3m 6s\tremaining: 8m 50s\n",
      "130:\tlearn: 0.4687242\ttotal: 3m 7s\tremaining: 8m 48s\n",
      "131:\tlearn: 0.4680792\ttotal: 3m 10s\tremaining: 8m 49s\n",
      "132:\tlearn: 0.4673582\ttotal: 3m 11s\tremaining: 8m 49s\n",
      "133:\tlearn: 0.4664997\ttotal: 3m 13s\tremaining: 8m 48s\n",
      "134:\tlearn: 0.4654370\ttotal: 3m 15s\tremaining: 8m 47s\n",
      "135:\tlearn: 0.4642910\ttotal: 3m 17s\tremaining: 8m 48s\n",
      "136:\tlearn: 0.4632532\ttotal: 3m 18s\tremaining: 8m 46s\n",
      "137:\tlearn: 0.4627000\ttotal: 3m 20s\tremaining: 8m 45s\n",
      "138:\tlearn: 0.4616329\ttotal: 3m 21s\tremaining: 8m 43s\n",
      "139:\tlearn: 0.4609554\ttotal: 3m 23s\tremaining: 8m 42s\n",
      "140:\tlearn: 0.4599519\ttotal: 3m 24s\tremaining: 8m 40s\n",
      "141:\tlearn: 0.4591692\ttotal: 3m 25s\tremaining: 8m 39s\n",
      "142:\tlearn: 0.4586614\ttotal: 3m 27s\tremaining: 8m 37s\n",
      "143:\tlearn: 0.4581164\ttotal: 3m 29s\tremaining: 8m 36s\n",
      "144:\tlearn: 0.4571409\ttotal: 3m 30s\tremaining: 8m 36s\n",
      "145:\tlearn: 0.4566081\ttotal: 3m 32s\tremaining: 8m 34s\n",
      "146:\tlearn: 0.4557601\ttotal: 3m 33s\tremaining: 8m 33s\n",
      "147:\tlearn: 0.4547601\ttotal: 3m 35s\tremaining: 8m 32s\n",
      "148:\tlearn: 0.4541598\ttotal: 3m 36s\tremaining: 8m 30s\n",
      "149:\tlearn: 0.4533428\ttotal: 3m 38s\tremaining: 8m 28s\n",
      "150:\tlearn: 0.4527106\ttotal: 3m 39s\tremaining: 8m 27s\n",
      "151:\tlearn: 0.4514687\ttotal: 3m 40s\tremaining: 8m 25s\n",
      "152:\tlearn: 0.4506042\ttotal: 3m 42s\tremaining: 8m 24s\n",
      "153:\tlearn: 0.4499638\ttotal: 3m 43s\tremaining: 8m 23s\n",
      "154:\tlearn: 0.4492691\ttotal: 3m 45s\tremaining: 8m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155:\tlearn: 0.4486363\ttotal: 3m 47s\tremaining: 8m 20s\n",
      "156:\tlearn: 0.4478823\ttotal: 3m 48s\tremaining: 8m 19s\n",
      "157:\tlearn: 0.4472611\ttotal: 3m 49s\tremaining: 8m 17s\n",
      "158:\tlearn: 0.4465636\ttotal: 3m 51s\tremaining: 8m 16s\n",
      "159:\tlearn: 0.4462417\ttotal: 3m 53s\tremaining: 8m 16s\n",
      "160:\tlearn: 0.4455467\ttotal: 3m 55s\tremaining: 8m 16s\n",
      "161:\tlearn: 0.4447235\ttotal: 3m 57s\tremaining: 8m 15s\n",
      "162:\tlearn: 0.4441007\ttotal: 3m 59s\tremaining: 8m 14s\n",
      "163:\tlearn: 0.4436340\ttotal: 4m 1s\tremaining: 8m 13s\n",
      "164:\tlearn: 0.4431906\ttotal: 4m 2s\tremaining: 8m 12s\n",
      "165:\tlearn: 0.4426075\ttotal: 4m 4s\tremaining: 8m 11s\n",
      "166:\tlearn: 0.4417544\ttotal: 4m 5s\tremaining: 8m 10s\n",
      "167:\tlearn: 0.4410355\ttotal: 4m 7s\tremaining: 8m 8s\n",
      "168:\tlearn: 0.4402824\ttotal: 4m 8s\tremaining: 8m 7s\n",
      "169:\tlearn: 0.4399454\ttotal: 4m 10s\tremaining: 8m 6s\n",
      "170:\tlearn: 0.4390238\ttotal: 4m 11s\tremaining: 8m 4s\n",
      "171:\tlearn: 0.4383416\ttotal: 4m 13s\tremaining: 8m 3s\n",
      "172:\tlearn: 0.4377242\ttotal: 4m 15s\tremaining: 8m 2s\n",
      "173:\tlearn: 0.4372289\ttotal: 4m 16s\tremaining: 8m 1s\n",
      "174:\tlearn: 0.4367591\ttotal: 4m 18s\tremaining: 7m 59s\n",
      "175:\tlearn: 0.4363410\ttotal: 4m 19s\tremaining: 7m 58s\n",
      "176:\tlearn: 0.4355318\ttotal: 4m 21s\tremaining: 7m 56s\n",
      "177:\tlearn: 0.4347673\ttotal: 4m 22s\tremaining: 7m 55s\n",
      "178:\tlearn: 0.4340269\ttotal: 4m 24s\tremaining: 7m 54s\n",
      "179:\tlearn: 0.4332965\ttotal: 4m 26s\tremaining: 7m 52s\n",
      "180:\tlearn: 0.4328359\ttotal: 4m 27s\tremaining: 7m 51s\n",
      "181:\tlearn: 0.4321939\ttotal: 4m 29s\tremaining: 7m 50s\n",
      "182:\tlearn: 0.4315537\ttotal: 4m 31s\tremaining: 7m 49s\n",
      "183:\tlearn: 0.4309020\ttotal: 4m 32s\tremaining: 7m 47s\n",
      "184:\tlearn: 0.4306074\ttotal: 4m 33s\tremaining: 7m 45s\n",
      "185:\tlearn: 0.4297168\ttotal: 4m 35s\tremaining: 7m 44s\n",
      "186:\tlearn: 0.4292513\ttotal: 4m 37s\tremaining: 7m 43s\n",
      "187:\tlearn: 0.4288999\ttotal: 4m 38s\tremaining: 7m 42s\n",
      "188:\tlearn: 0.4284396\ttotal: 4m 40s\tremaining: 7m 40s\n",
      "189:\tlearn: 0.4281046\ttotal: 4m 42s\tremaining: 7m 40s\n",
      "190:\tlearn: 0.4277206\ttotal: 4m 43s\tremaining: 7m 38s\n",
      "191:\tlearn: 0.4272271\ttotal: 4m 44s\tremaining: 7m 36s\n",
      "192:\tlearn: 0.4264260\ttotal: 4m 46s\tremaining: 7m 35s\n",
      "193:\tlearn: 0.4261628\ttotal: 4m 47s\tremaining: 7m 33s\n",
      "194:\tlearn: 0.4258862\ttotal: 4m 49s\tremaining: 7m 32s\n",
      "195:\tlearn: 0.4255414\ttotal: 4m 50s\tremaining: 7m 30s\n",
      "196:\tlearn: 0.4252333\ttotal: 4m 52s\tremaining: 7m 29s\n",
      "197:\tlearn: 0.4249093\ttotal: 4m 53s\tremaining: 7m 27s\n",
      "198:\tlearn: 0.4244423\ttotal: 4m 55s\tremaining: 7m 26s\n",
      "199:\tlearn: 0.4236727\ttotal: 4m 56s\tremaining: 7m 25s\n",
      "200:\tlearn: 0.4231044\ttotal: 4m 58s\tremaining: 7m 24s\n",
      "201:\tlearn: 0.4226223\ttotal: 5m\tremaining: 7m 23s\n",
      "202:\tlearn: 0.4222784\ttotal: 5m 2s\tremaining: 7m 22s\n",
      "203:\tlearn: 0.4220519\ttotal: 5m 3s\tremaining: 7m 20s\n",
      "204:\tlearn: 0.4214884\ttotal: 5m 5s\tremaining: 7m 19s\n",
      "205:\tlearn: 0.4210688\ttotal: 5m 7s\tremaining: 7m 18s\n",
      "206:\tlearn: 0.4207049\ttotal: 5m 9s\tremaining: 7m 17s\n",
      "207:\tlearn: 0.4202919\ttotal: 5m 11s\tremaining: 7m 16s\n",
      "208:\tlearn: 0.4200397\ttotal: 5m 12s\tremaining: 7m 15s\n",
      "209:\tlearn: 0.4197414\ttotal: 5m 14s\tremaining: 7m 14s\n",
      "210:\tlearn: 0.4191641\ttotal: 5m 16s\tremaining: 7m 13s\n",
      "211:\tlearn: 0.4188156\ttotal: 5m 17s\tremaining: 7m 11s\n",
      "212:\tlearn: 0.4187548\ttotal: 5m 19s\tremaining: 7m 10s\n",
      "213:\tlearn: 0.4185861\ttotal: 5m 20s\tremaining: 7m 8s\n",
      "214:\tlearn: 0.4181738\ttotal: 5m 22s\tremaining: 7m 7s\n",
      "215:\tlearn: 0.4177621\ttotal: 5m 23s\tremaining: 7m 5s\n",
      "216:\tlearn: 0.4175955\ttotal: 5m 25s\tremaining: 7m 3s\n",
      "217:\tlearn: 0.4173929\ttotal: 5m 26s\tremaining: 7m 2s\n",
      "218:\tlearn: 0.4171399\ttotal: 5m 27s\tremaining: 7m\n",
      "219:\tlearn: 0.4167161\ttotal: 5m 29s\tremaining: 6m 59s\n",
      "220:\tlearn: 0.4165228\ttotal: 5m 30s\tremaining: 6m 57s\n",
      "221:\tlearn: 0.4163625\ttotal: 5m 31s\tremaining: 6m 55s\n",
      "222:\tlearn: 0.4161616\ttotal: 5m 33s\tremaining: 6m 54s\n",
      "223:\tlearn: 0.4160652\ttotal: 5m 35s\tremaining: 6m 52s\n",
      "224:\tlearn: 0.4158596\ttotal: 5m 36s\tremaining: 6m 51s\n",
      "225:\tlearn: 0.4151294\ttotal: 5m 37s\tremaining: 6m 49s\n",
      "226:\tlearn: 0.4147070\ttotal: 5m 39s\tremaining: 6m 47s\n",
      "227:\tlearn: 0.4140193\ttotal: 5m 40s\tremaining: 6m 46s\n",
      "228:\tlearn: 0.4133587\ttotal: 5m 42s\tremaining: 6m 45s\n",
      "229:\tlearn: 0.4131746\ttotal: 5m 43s\tremaining: 6m 43s\n",
      "230:\tlearn: 0.4127526\ttotal: 5m 45s\tremaining: 6m 42s\n",
      "231:\tlearn: 0.4122903\ttotal: 5m 46s\tremaining: 6m 40s\n",
      "232:\tlearn: 0.4118646\ttotal: 5m 48s\tremaining: 6m 39s\n",
      "233:\tlearn: 0.4114980\ttotal: 5m 50s\tremaining: 6m 37s\n",
      "234:\tlearn: 0.4109460\ttotal: 5m 51s\tremaining: 6m 36s\n",
      "235:\tlearn: 0.4106667\ttotal: 5m 53s\tremaining: 6m 35s\n",
      "236:\tlearn: 0.4104922\ttotal: 5m 54s\tremaining: 6m 33s\n",
      "237:\tlearn: 0.4100210\ttotal: 5m 56s\tremaining: 6m 32s\n",
      "238:\tlearn: 0.4097127\ttotal: 5m 58s\tremaining: 6m 31s\n",
      "239:\tlearn: 0.4092654\ttotal: 5m 59s\tremaining: 6m 29s\n",
      "240:\tlearn: 0.4089548\ttotal: 6m 1s\tremaining: 6m 28s\n",
      "241:\tlearn: 0.4084261\ttotal: 6m 3s\tremaining: 6m 27s\n",
      "242:\tlearn: 0.4077826\ttotal: 6m 4s\tremaining: 6m 25s\n",
      "243:\tlearn: 0.4075682\ttotal: 6m 6s\tremaining: 6m 24s\n",
      "244:\tlearn: 0.4073290\ttotal: 6m 7s\tremaining: 6m 22s\n",
      "245:\tlearn: 0.4069072\ttotal: 6m 9s\tremaining: 6m 21s\n",
      "246:\tlearn: 0.4066376\ttotal: 6m 11s\tremaining: 6m 20s\n",
      "247:\tlearn: 0.4063234\ttotal: 6m 12s\tremaining: 6m 18s\n",
      "248:\tlearn: 0.4058990\ttotal: 6m 14s\tremaining: 6m 17s\n",
      "249:\tlearn: 0.4057530\ttotal: 6m 15s\tremaining: 6m 15s\n",
      "250:\tlearn: 0.4053656\ttotal: 6m 17s\tremaining: 6m 14s\n",
      "251:\tlearn: 0.4050160\ttotal: 6m 19s\tremaining: 6m 13s\n",
      "252:\tlearn: 0.4047557\ttotal: 6m 20s\tremaining: 6m 11s\n",
      "253:\tlearn: 0.4043729\ttotal: 6m 22s\tremaining: 6m 10s\n",
      "254:\tlearn: 0.4038765\ttotal: 6m 23s\tremaining: 6m 8s\n",
      "255:\tlearn: 0.4035354\ttotal: 6m 25s\tremaining: 6m 7s\n",
      "256:\tlearn: 0.4032534\ttotal: 6m 27s\tremaining: 6m 6s\n",
      "257:\tlearn: 0.4030784\ttotal: 6m 28s\tremaining: 6m 4s\n",
      "258:\tlearn: 0.4028331\ttotal: 6m 30s\tremaining: 6m 3s\n",
      "259:\tlearn: 0.4026335\ttotal: 6m 32s\tremaining: 6m 2s\n",
      "260:\tlearn: 0.4022882\ttotal: 6m 33s\tremaining: 6m\n",
      "261:\tlearn: 0.4018266\ttotal: 6m 35s\tremaining: 5m 59s\n",
      "262:\tlearn: 0.4016472\ttotal: 6m 36s\tremaining: 5m 57s\n",
      "263:\tlearn: 0.4013760\ttotal: 6m 38s\tremaining: 5m 55s\n",
      "264:\tlearn: 0.4011945\ttotal: 6m 39s\tremaining: 5m 54s\n",
      "265:\tlearn: 0.4006749\ttotal: 6m 40s\tremaining: 5m 52s\n",
      "266:\tlearn: 0.4005863\ttotal: 6m 42s\tremaining: 5m 51s\n",
      "267:\tlearn: 0.4002127\ttotal: 6m 43s\tremaining: 5m 49s\n",
      "268:\tlearn: 0.3996736\ttotal: 6m 45s\tremaining: 5m 47s\n",
      "269:\tlearn: 0.3993512\ttotal: 6m 46s\tremaining: 5m 46s\n",
      "270:\tlearn: 0.3990174\ttotal: 6m 47s\tremaining: 5m 44s\n",
      "271:\tlearn: 0.3986628\ttotal: 6m 49s\tremaining: 5m 42s\n",
      "272:\tlearn: 0.3985033\ttotal: 6m 50s\tremaining: 5m 41s\n",
      "273:\tlearn: 0.3981953\ttotal: 6m 51s\tremaining: 5m 39s\n",
      "274:\tlearn: 0.3979952\ttotal: 6m 53s\tremaining: 5m 38s\n",
      "275:\tlearn: 0.3973467\ttotal: 6m 54s\tremaining: 5m 36s\n",
      "276:\tlearn: 0.3970350\ttotal: 6m 56s\tremaining: 5m 35s\n",
      "277:\tlearn: 0.3967885\ttotal: 6m 57s\tremaining: 5m 33s\n",
      "278:\tlearn: 0.3965912\ttotal: 6m 58s\tremaining: 5m 31s\n",
      "279:\tlearn: 0.3961492\ttotal: 7m\tremaining: 5m 30s\n",
      "280:\tlearn: 0.3959769\ttotal: 7m 1s\tremaining: 5m 28s\n",
      "281:\tlearn: 0.3958327\ttotal: 7m 3s\tremaining: 5m 27s\n",
      "282:\tlearn: 0.3954580\ttotal: 7m 4s\tremaining: 5m 25s\n",
      "283:\tlearn: 0.3951040\ttotal: 7m 5s\tremaining: 5m 23s\n",
      "284:\tlearn: 0.3946990\ttotal: 7m 7s\tremaining: 5m 22s\n",
      "285:\tlearn: 0.3945642\ttotal: 7m 8s\tremaining: 5m 20s\n",
      "286:\tlearn: 0.3941493\ttotal: 7m 9s\tremaining: 5m 19s\n",
      "287:\tlearn: 0.3938626\ttotal: 7m 11s\tremaining: 5m 17s\n",
      "288:\tlearn: 0.3937052\ttotal: 7m 12s\tremaining: 5m 15s\n",
      "289:\tlearn: 0.3933490\ttotal: 7m 14s\tremaining: 5m 14s\n",
      "290:\tlearn: 0.3932659\ttotal: 7m 15s\tremaining: 5m 12s\n",
      "291:\tlearn: 0.3928625\ttotal: 7m 16s\tremaining: 5m 11s\n",
      "292:\tlearn: 0.3926815\ttotal: 7m 18s\tremaining: 5m 9s\n",
      "293:\tlearn: 0.3923672\ttotal: 7m 19s\tremaining: 5m 7s\n",
      "294:\tlearn: 0.3920834\ttotal: 7m 20s\tremaining: 5m 6s\n",
      "295:\tlearn: 0.3917953\ttotal: 7m 22s\tremaining: 5m 4s\n",
      "296:\tlearn: 0.3914909\ttotal: 7m 23s\tremaining: 5m 3s\n",
      "297:\tlearn: 0.3913029\ttotal: 7m 24s\tremaining: 5m 1s\n",
      "298:\tlearn: 0.3910665\ttotal: 7m 26s\tremaining: 4m 59s\n",
      "299:\tlearn: 0.3906075\ttotal: 7m 27s\tremaining: 4m 58s\n",
      "300:\tlearn: 0.3903028\ttotal: 7m 29s\tremaining: 4m 56s\n",
      "301:\tlearn: 0.3900684\ttotal: 7m 30s\tremaining: 4m 55s\n",
      "302:\tlearn: 0.3895924\ttotal: 7m 31s\tremaining: 4m 53s\n",
      "303:\tlearn: 0.3893384\ttotal: 7m 33s\tremaining: 4m 52s\n",
      "304:\tlearn: 0.3892351\ttotal: 7m 34s\tremaining: 4m 50s\n",
      "305:\tlearn: 0.3890484\ttotal: 7m 35s\tremaining: 4m 48s\n",
      "306:\tlearn: 0.3886928\ttotal: 7m 37s\tremaining: 4m 47s\n",
      "307:\tlearn: 0.3883742\ttotal: 7m 38s\tremaining: 4m 45s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308:\tlearn: 0.3881452\ttotal: 7m 39s\tremaining: 4m 44s\n",
      "309:\tlearn: 0.3878622\ttotal: 7m 41s\tremaining: 4m 42s\n",
      "310:\tlearn: 0.3874028\ttotal: 7m 42s\tremaining: 4m 41s\n",
      "311:\tlearn: 0.3872639\ttotal: 7m 43s\tremaining: 4m 39s\n",
      "312:\tlearn: 0.3870422\ttotal: 7m 45s\tremaining: 4m 37s\n",
      "313:\tlearn: 0.3868254\ttotal: 7m 46s\tremaining: 4m 36s\n",
      "314:\tlearn: 0.3865123\ttotal: 7m 48s\tremaining: 4m 34s\n",
      "315:\tlearn: 0.3863796\ttotal: 7m 49s\tremaining: 4m 33s\n",
      "316:\tlearn: 0.3861773\ttotal: 7m 50s\tremaining: 4m 31s\n",
      "317:\tlearn: 0.3857624\ttotal: 7m 52s\tremaining: 4m 30s\n",
      "318:\tlearn: 0.3853348\ttotal: 7m 53s\tremaining: 4m 28s\n",
      "319:\tlearn: 0.3851012\ttotal: 7m 55s\tremaining: 4m 27s\n",
      "320:\tlearn: 0.3846540\ttotal: 7m 56s\tremaining: 4m 25s\n",
      "321:\tlearn: 0.3845747\ttotal: 7m 58s\tremaining: 4m 24s\n",
      "322:\tlearn: 0.3841985\ttotal: 7m 59s\tremaining: 4m 22s\n",
      "323:\tlearn: 0.3841222\ttotal: 8m 1s\tremaining: 4m 21s\n",
      "324:\tlearn: 0.3839803\ttotal: 8m 2s\tremaining: 4m 19s\n",
      "325:\tlearn: 0.3836035\ttotal: 8m 3s\tremaining: 4m 18s\n",
      "326:\tlearn: 0.3834838\ttotal: 8m 5s\tremaining: 4m 16s\n",
      "327:\tlearn: 0.3832045\ttotal: 8m 6s\tremaining: 4m 15s\n",
      "328:\tlearn: 0.3830842\ttotal: 8m 7s\tremaining: 4m 13s\n",
      "329:\tlearn: 0.3828650\ttotal: 8m 9s\tremaining: 4m 11s\n",
      "330:\tlearn: 0.3826356\ttotal: 8m 10s\tremaining: 4m 10s\n",
      "331:\tlearn: 0.3824369\ttotal: 8m 11s\tremaining: 4m 8s\n",
      "332:\tlearn: 0.3822689\ttotal: 8m 13s\tremaining: 4m 7s\n",
      "333:\tlearn: 0.3821278\ttotal: 8m 14s\tremaining: 4m 5s\n",
      "334:\tlearn: 0.3818003\ttotal: 8m 15s\tremaining: 4m 4s\n",
      "335:\tlearn: 0.3811740\ttotal: 8m 17s\tremaining: 4m 2s\n",
      "336:\tlearn: 0.3808910\ttotal: 8m 18s\tremaining: 4m 1s\n",
      "337:\tlearn: 0.3807422\ttotal: 8m 19s\tremaining: 3m 59s\n",
      "338:\tlearn: 0.3803697\ttotal: 8m 20s\tremaining: 3m 57s\n",
      "339:\tlearn: 0.3799607\ttotal: 8m 22s\tremaining: 3m 56s\n",
      "340:\tlearn: 0.3797337\ttotal: 8m 23s\tremaining: 3m 54s\n",
      "341:\tlearn: 0.3794463\ttotal: 8m 24s\tremaining: 3m 53s\n",
      "342:\tlearn: 0.3793181\ttotal: 8m 26s\tremaining: 3m 51s\n",
      "343:\tlearn: 0.3791525\ttotal: 8m 27s\tremaining: 3m 50s\n",
      "344:\tlearn: 0.3787875\ttotal: 8m 28s\tremaining: 3m 48s\n",
      "345:\tlearn: 0.3786515\ttotal: 8m 30s\tremaining: 3m 47s\n",
      "346:\tlearn: 0.3786054\ttotal: 8m 31s\tremaining: 3m 45s\n",
      "347:\tlearn: 0.3781025\ttotal: 8m 32s\tremaining: 3m 44s\n",
      "348:\tlearn: 0.3778999\ttotal: 8m 34s\tremaining: 3m 42s\n",
      "349:\tlearn: 0.3775777\ttotal: 8m 35s\tremaining: 3m 40s\n",
      "350:\tlearn: 0.3773448\ttotal: 8m 36s\tremaining: 3m 39s\n",
      "351:\tlearn: 0.3769779\ttotal: 8m 38s\tremaining: 3m 37s\n",
      "352:\tlearn: 0.3766754\ttotal: 8m 39s\tremaining: 3m 36s\n",
      "353:\tlearn: 0.3764010\ttotal: 8m 40s\tremaining: 3m 34s\n",
      "354:\tlearn: 0.3762775\ttotal: 8m 42s\tremaining: 3m 33s\n",
      "355:\tlearn: 0.3760624\ttotal: 8m 43s\tremaining: 3m 31s\n",
      "356:\tlearn: 0.3754042\ttotal: 8m 45s\tremaining: 3m 30s\n",
      "357:\tlearn: 0.3750249\ttotal: 8m 46s\tremaining: 3m 28s\n",
      "358:\tlearn: 0.3748636\ttotal: 8m 47s\tremaining: 3m 27s\n",
      "359:\tlearn: 0.3747030\ttotal: 8m 48s\tremaining: 3m 25s\n",
      "360:\tlearn: 0.3742094\ttotal: 8m 49s\tremaining: 3m 24s\n",
      "361:\tlearn: 0.3737016\ttotal: 8m 51s\tremaining: 3m 22s\n",
      "362:\tlearn: 0.3734578\ttotal: 8m 52s\tremaining: 3m 20s\n",
      "363:\tlearn: 0.3732564\ttotal: 8m 53s\tremaining: 3m 19s\n",
      "364:\tlearn: 0.3730659\ttotal: 8m 55s\tremaining: 3m 17s\n",
      "365:\tlearn: 0.3729526\ttotal: 8m 56s\tremaining: 3m 16s\n",
      "366:\tlearn: 0.3727443\ttotal: 8m 57s\tremaining: 3m 14s\n",
      "367:\tlearn: 0.3726492\ttotal: 8m 59s\tremaining: 3m 13s\n",
      "368:\tlearn: 0.3725419\ttotal: 9m\tremaining: 3m 11s\n",
      "369:\tlearn: 0.3724865\ttotal: 9m 1s\tremaining: 3m 10s\n",
      "370:\tlearn: 0.3722440\ttotal: 9m 3s\tremaining: 3m 8s\n",
      "371:\tlearn: 0.3720736\ttotal: 9m 4s\tremaining: 3m 7s\n",
      "372:\tlearn: 0.3717358\ttotal: 9m 5s\tremaining: 3m 5s\n",
      "373:\tlearn: 0.3716146\ttotal: 9m 6s\tremaining: 3m 4s\n",
      "374:\tlearn: 0.3714733\ttotal: 9m 8s\tremaining: 3m 2s\n",
      "375:\tlearn: 0.3712158\ttotal: 9m 9s\tremaining: 3m 1s\n",
      "376:\tlearn: 0.3710071\ttotal: 9m 10s\tremaining: 2m 59s\n",
      "377:\tlearn: 0.3707897\ttotal: 9m 12s\tremaining: 2m 58s\n",
      "378:\tlearn: 0.3706558\ttotal: 9m 13s\tremaining: 2m 56s\n",
      "379:\tlearn: 0.3704876\ttotal: 9m 14s\tremaining: 2m 55s\n",
      "380:\tlearn: 0.3701827\ttotal: 9m 16s\tremaining: 2m 53s\n",
      "381:\tlearn: 0.3700492\ttotal: 9m 17s\tremaining: 2m 52s\n",
      "382:\tlearn: 0.3698922\ttotal: 9m 19s\tremaining: 2m 50s\n",
      "383:\tlearn: 0.3697138\ttotal: 9m 20s\tremaining: 2m 49s\n",
      "384:\tlearn: 0.3695200\ttotal: 9m 21s\tremaining: 2m 47s\n",
      "385:\tlearn: 0.3692075\ttotal: 9m 23s\tremaining: 2m 46s\n",
      "386:\tlearn: 0.3689031\ttotal: 9m 24s\tremaining: 2m 44s\n",
      "387:\tlearn: 0.3688573\ttotal: 9m 26s\tremaining: 2m 43s\n",
      "388:\tlearn: 0.3686980\ttotal: 9m 27s\tremaining: 2m 41s\n",
      "389:\tlearn: 0.3684290\ttotal: 9m 28s\tremaining: 2m 40s\n",
      "390:\tlearn: 0.3683560\ttotal: 9m 30s\tremaining: 2m 38s\n",
      "391:\tlearn: 0.3681621\ttotal: 9m 31s\tremaining: 2m 37s\n",
      "392:\tlearn: 0.3679221\ttotal: 9m 32s\tremaining: 2m 35s\n",
      "393:\tlearn: 0.3677414\ttotal: 9m 34s\tremaining: 2m 34s\n",
      "394:\tlearn: 0.3675051\ttotal: 9m 35s\tremaining: 2m 33s\n",
      "395:\tlearn: 0.3671657\ttotal: 9m 37s\tremaining: 2m 31s\n",
      "396:\tlearn: 0.3668969\ttotal: 9m 39s\tremaining: 2m 30s\n",
      "397:\tlearn: 0.3665031\ttotal: 9m 40s\tremaining: 2m 28s\n",
      "398:\tlearn: 0.3661771\ttotal: 9m 42s\tremaining: 2m 27s\n",
      "399:\tlearn: 0.3659668\ttotal: 9m 43s\tremaining: 2m 25s\n",
      "400:\tlearn: 0.3657331\ttotal: 9m 44s\tremaining: 2m 24s\n",
      "401:\tlearn: 0.3656605\ttotal: 9m 46s\tremaining: 2m 22s\n",
      "402:\tlearn: 0.3654070\ttotal: 9m 47s\tremaining: 2m 21s\n",
      "403:\tlearn: 0.3652560\ttotal: 9m 49s\tremaining: 2m 19s\n",
      "404:\tlearn: 0.3651640\ttotal: 9m 50s\tremaining: 2m 18s\n",
      "405:\tlearn: 0.3648537\ttotal: 9m 51s\tremaining: 2m 17s\n",
      "406:\tlearn: 0.3645680\ttotal: 9m 53s\tremaining: 2m 15s\n",
      "407:\tlearn: 0.3644187\ttotal: 9m 54s\tremaining: 2m 14s\n",
      "408:\tlearn: 0.3643122\ttotal: 9m 55s\tremaining: 2m 12s\n",
      "409:\tlearn: 0.3641350\ttotal: 9m 57s\tremaining: 2m 11s\n",
      "410:\tlearn: 0.3640302\ttotal: 9m 58s\tremaining: 2m 9s\n",
      "411:\tlearn: 0.3639371\ttotal: 9m 59s\tremaining: 2m 8s\n",
      "412:\tlearn: 0.3636862\ttotal: 10m 1s\tremaining: 2m 6s\n",
      "413:\tlearn: 0.3636033\ttotal: 10m 2s\tremaining: 2m 5s\n",
      "414:\tlearn: 0.3635409\ttotal: 10m 4s\tremaining: 2m 3s\n",
      "415:\tlearn: 0.3634761\ttotal: 10m 5s\tremaining: 2m 2s\n",
      "416:\tlearn: 0.3632055\ttotal: 10m 7s\tremaining: 2m\n",
      "417:\tlearn: 0.3629992\ttotal: 10m 8s\tremaining: 1m 59s\n",
      "418:\tlearn: 0.3627014\ttotal: 10m 9s\tremaining: 1m 57s\n",
      "419:\tlearn: 0.3625909\ttotal: 10m 11s\tremaining: 1m 56s\n",
      "420:\tlearn: 0.3624277\ttotal: 10m 12s\tremaining: 1m 54s\n",
      "421:\tlearn: 0.3623676\ttotal: 10m 13s\tremaining: 1m 53s\n",
      "422:\tlearn: 0.3622956\ttotal: 10m 15s\tremaining: 1m 52s\n",
      "423:\tlearn: 0.3619585\ttotal: 10m 16s\tremaining: 1m 50s\n",
      "424:\tlearn: 0.3618168\ttotal: 10m 16s\tremaining: 1m 48s\n",
      "425:\tlearn: 0.3615686\ttotal: 10m 18s\tremaining: 1m 47s\n",
      "426:\tlearn: 0.3613281\ttotal: 10m 19s\tremaining: 1m 45s\n",
      "427:\tlearn: 0.3611325\ttotal: 10m 20s\tremaining: 1m 44s\n",
      "428:\tlearn: 0.3610063\ttotal: 10m 22s\tremaining: 1m 42s\n",
      "429:\tlearn: 0.3608951\ttotal: 10m 23s\tremaining: 1m 41s\n",
      "430:\tlearn: 0.3607728\ttotal: 10m 24s\tremaining: 1m 40s\n",
      "431:\tlearn: 0.3605556\ttotal: 10m 26s\tremaining: 1m 38s\n",
      "432:\tlearn: 0.3604960\ttotal: 10m 27s\tremaining: 1m 37s\n",
      "433:\tlearn: 0.3603792\ttotal: 10m 29s\tremaining: 1m 35s\n",
      "434:\tlearn: 0.3602394\ttotal: 10m 30s\tremaining: 1m 34s\n",
      "435:\tlearn: 0.3599589\ttotal: 10m 31s\tremaining: 1m 32s\n",
      "436:\tlearn: 0.3596608\ttotal: 10m 33s\tremaining: 1m 31s\n",
      "437:\tlearn: 0.3595364\ttotal: 10m 34s\tremaining: 1m 29s\n",
      "438:\tlearn: 0.3593746\ttotal: 10m 35s\tremaining: 1m 28s\n",
      "439:\tlearn: 0.3592514\ttotal: 10m 37s\tremaining: 1m 26s\n",
      "440:\tlearn: 0.3590097\ttotal: 10m 38s\tremaining: 1m 25s\n",
      "441:\tlearn: 0.3588652\ttotal: 10m 40s\tremaining: 1m 24s\n",
      "442:\tlearn: 0.3587548\ttotal: 10m 41s\tremaining: 1m 22s\n",
      "443:\tlearn: 0.3584241\ttotal: 10m 42s\tremaining: 1m 21s\n",
      "444:\tlearn: 0.3582768\ttotal: 10m 44s\tremaining: 1m 19s\n",
      "445:\tlearn: 0.3579376\ttotal: 10m 45s\tremaining: 1m 18s\n",
      "446:\tlearn: 0.3578471\ttotal: 10m 47s\tremaining: 1m 16s\n",
      "447:\tlearn: 0.3575508\ttotal: 10m 48s\tremaining: 1m 15s\n",
      "448:\tlearn: 0.3573489\ttotal: 10m 49s\tremaining: 1m 13s\n",
      "449:\tlearn: 0.3571859\ttotal: 10m 51s\tremaining: 1m 12s\n",
      "450:\tlearn: 0.3569943\ttotal: 10m 52s\tremaining: 1m 10s\n",
      "451:\tlearn: 0.3567730\ttotal: 10m 53s\tremaining: 1m 9s\n",
      "452:\tlearn: 0.3566519\ttotal: 10m 55s\tremaining: 1m 7s\n",
      "453:\tlearn: 0.3564121\ttotal: 10m 56s\tremaining: 1m 6s\n",
      "454:\tlearn: 0.3562114\ttotal: 10m 57s\tremaining: 1m 5s\n",
      "455:\tlearn: 0.3559166\ttotal: 10m 59s\tremaining: 1m 3s\n",
      "456:\tlearn: 0.3556779\ttotal: 11m\tremaining: 1m 2s\n",
      "457:\tlearn: 0.3553437\ttotal: 11m 1s\tremaining: 1m\n",
      "458:\tlearn: 0.3552808\ttotal: 11m 3s\tremaining: 59.3s\n",
      "459:\tlearn: 0.3552120\ttotal: 11m 4s\tremaining: 57.8s\n",
      "460:\tlearn: 0.3550352\ttotal: 11m 6s\tremaining: 56.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461:\tlearn: 0.3547970\ttotal: 11m 7s\tremaining: 54.9s\n",
      "462:\tlearn: 0.3545668\ttotal: 11m 8s\tremaining: 53.4s\n",
      "463:\tlearn: 0.3544337\ttotal: 11m 10s\tremaining: 52s\n",
      "464:\tlearn: 0.3542948\ttotal: 11m 11s\tremaining: 50.6s\n",
      "465:\tlearn: 0.3541478\ttotal: 11m 13s\tremaining: 49.1s\n",
      "466:\tlearn: 0.3540503\ttotal: 11m 14s\tremaining: 47.7s\n",
      "467:\tlearn: 0.3539083\ttotal: 11m 15s\tremaining: 46.2s\n",
      "468:\tlearn: 0.3535783\ttotal: 11m 17s\tremaining: 44.8s\n",
      "469:\tlearn: 0.3533562\ttotal: 11m 18s\tremaining: 43.3s\n",
      "470:\tlearn: 0.3530115\ttotal: 11m 19s\tremaining: 41.9s\n",
      "471:\tlearn: 0.3528997\ttotal: 11m 21s\tremaining: 40.4s\n",
      "472:\tlearn: 0.3528435\ttotal: 11m 22s\tremaining: 39s\n",
      "473:\tlearn: 0.3526643\ttotal: 11m 23s\tremaining: 37.5s\n",
      "474:\tlearn: 0.3523901\ttotal: 11m 25s\tremaining: 36.1s\n",
      "475:\tlearn: 0.3521556\ttotal: 11m 26s\tremaining: 34.6s\n",
      "476:\tlearn: 0.3518065\ttotal: 11m 28s\tremaining: 33.2s\n",
      "477:\tlearn: 0.3515334\ttotal: 11m 29s\tremaining: 31.7s\n",
      "478:\tlearn: 0.3512122\ttotal: 11m 31s\tremaining: 30.3s\n",
      "479:\tlearn: 0.3510789\ttotal: 11m 32s\tremaining: 28.9s\n",
      "480:\tlearn: 0.3509792\ttotal: 11m 33s\tremaining: 27.4s\n",
      "481:\tlearn: 0.3508461\ttotal: 11m 35s\tremaining: 26s\n",
      "482:\tlearn: 0.3507042\ttotal: 11m 36s\tremaining: 24.5s\n",
      "483:\tlearn: 0.3506178\ttotal: 11m 37s\tremaining: 23.1s\n",
      "484:\tlearn: 0.3505031\ttotal: 11m 39s\tremaining: 21.6s\n",
      "485:\tlearn: 0.3502560\ttotal: 11m 40s\tremaining: 20.2s\n",
      "486:\tlearn: 0.3499815\ttotal: 11m 41s\tremaining: 18.7s\n",
      "487:\tlearn: 0.3499352\ttotal: 11m 43s\tremaining: 17.3s\n",
      "488:\tlearn: 0.3498034\ttotal: 11m 44s\tremaining: 15.8s\n",
      "489:\tlearn: 0.3496806\ttotal: 11m 45s\tremaining: 14.4s\n",
      "490:\tlearn: 0.3495322\ttotal: 11m 47s\tremaining: 13s\n",
      "491:\tlearn: 0.3494272\ttotal: 11m 48s\tremaining: 11.5s\n",
      "492:\tlearn: 0.3493385\ttotal: 11m 49s\tremaining: 10.1s\n",
      "493:\tlearn: 0.3491410\ttotal: 11m 51s\tremaining: 8.64s\n",
      "494:\tlearn: 0.3487493\ttotal: 11m 52s\tremaining: 7.2s\n",
      "495:\tlearn: 0.3486985\ttotal: 11m 53s\tremaining: 5.76s\n",
      "496:\tlearn: 0.3486303\ttotal: 11m 55s\tremaining: 4.32s\n",
      "497:\tlearn: 0.3485400\ttotal: 11m 56s\tremaining: 2.88s\n",
      "498:\tlearn: 0.3483252\ttotal: 11m 58s\tremaining: 1.44s\n",
      "499:\tlearn: 0.3482051\ttotal: 11m 59s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x26d58616a90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bestmodel 생성\n",
    "best_model = CatBoostClassifier(depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.05)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.890\n",
      "test score: 0.846\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_test_hat = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"test score: %.3f\" %test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**그러나 catBoost 모델의 경우 계산 비용이 너무커서 random forest 모델을 쓰는 것이 좋을 수도 있겠다.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
