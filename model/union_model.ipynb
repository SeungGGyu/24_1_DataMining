{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. data 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 최종적으로 cluster된 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\대학\\3학년 1학기\\데이터마이닝\\프로젝트\\new_df.csv\", encoding = 'cp949') \n",
    "#재난분류문자_클러스스터링_최종.ipynb 파일으로부터 나온 파일."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5608, 1) y_train shape: (5608,)\n",
      "X_valid shape: (1870, 1) y_valid shape: (1870,)\n",
      "X_test shape: (1870, 1) y_test shape: (1870,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 'label' 열을 삭제하고 결과를 df 변수에 저장\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# train : val : test = 6 : 2 : 2\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape, \"y_valid shape:\", y_valid.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 분할된 각 set ->  tf-idf 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-1) train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋 벡터화\n",
    "train_texts = X_train['preprocessed_송출내용'].fillna('')\n",
    "vectorizer = TfidfVectorizer(max_features=30)\n",
    "vectored_train = vectorizer.fit_transform(train_texts).todense()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "X_train_vectored = pd.DataFrame(vectored_train, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-2) valid set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid 데이터셋 벡터화\n",
    "valid_texts = X_valid['preprocessed_송출내용'].fillna('')\n",
    "vectored_valid = vectorizer.transform(valid_texts).todense()\n",
    "X_valid_vectored = pd.DataFrame(vectored_valid, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-3) test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터셋 벡터화\n",
    "test_texts = X_test['preprocessed_송출내용'].fillna('')\n",
    "vectored_test = vectorizer.transform(test_texts).todense()\n",
    "X_test_vectored = pd.DataFrame(vectored_test, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) set별 data scaling (model에 따라 scaled 된 data가 필요한 경우가 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vectored)\n",
    "X_valid_scaled = scaler.transform(X_valid_vectored)\n",
    "X_test_scaled = scaler.transform(X_test_vectored)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 모델 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.870\n",
      "valid score: 0.817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_hat = svc.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = svc.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) svc 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for문으로 탐색.** <br/>\n",
    "**1-1) C, gamma 조절**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.783957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.756419</td>\n",
       "      <td>0.731551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.600036</td>\n",
       "      <td>0.574866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.901213</td>\n",
       "      <td>0.832086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.829886</td>\n",
       "      <td>0.792513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.748395</td>\n",
       "      <td>0.725668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.604315</td>\n",
       "      <td>0.577540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>0.839037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.880350</td>\n",
       "      <td>0.817112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.803495</td>\n",
       "      <td>0.770053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.746969</td>\n",
       "      <td>0.721390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.926890</td>\n",
       "      <td>0.839037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.909058</td>\n",
       "      <td>0.824064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.827746</td>\n",
       "      <td>0.782888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.783167</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C   gamma  train_accuracy  valid_accuracy\n",
       "0    0.1  0.1000        0.809201        0.783957\n",
       "1    0.1  0.0100        0.756419        0.731551\n",
       "2    0.1  0.0010        0.600036        0.574866\n",
       "3    0.1  0.0001        0.324358        0.324599\n",
       "4    1.0  0.1000        0.901213        0.832086\n",
       "5    1.0  0.0100        0.829886        0.792513\n",
       "6    1.0  0.0010        0.748395        0.725668\n",
       "7    1.0  0.0001        0.604315        0.577540\n",
       "8   10.0  0.1000        0.925999        0.839037\n",
       "9   10.0  0.0100        0.880350        0.817112\n",
       "10  10.0  0.0010        0.803495        0.770053\n",
       "11  10.0  0.0001        0.746969        0.721390\n",
       "12  50.0  0.1000        0.926890        0.839037\n",
       "13  50.0  0.0100        0.909058        0.824064\n",
       "14  50.0  0.0010        0.827746        0.782888\n",
       "15  50.0  0.0001        0.783167        0.759358"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_settings = [0.1, 1, 10, 50]\n",
    "gamma_settings = [0.1, 0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for C in C_settings:\n",
    "    for gamma in gamma_settings:\n",
    "        svc = SVC(C=C, gamma=gamma, random_state=20).fit(X_train_scaled, y_train) #C, gamma 조정\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'C': C,\n",
    "                        'gamma': gamma,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적 hyperparameter:  kernel = poly, C = 50.0, gamma=0.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 SVC model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.927\n",
      "valid score: 0.839\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_svc = SVC(C=50, gamma=0.1).fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_svc.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_svc.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       152\n",
      "           1       0.73      0.75      0.74       162\n",
      "           2       0.64      0.61      0.62        89\n",
      "           3       0.70      0.59      0.64        51\n",
      "           4       0.81      0.83      0.82       607\n",
      "           5       0.97      0.95      0.96       464\n",
      "           6       0.77      0.86      0.81       194\n",
      "           7       0.84      0.75      0.79       151\n",
      "\n",
      "    accuracy                           0.84      1870\n",
      "   macro avg       0.80      0.78      0.79      1870\n",
      "weighted avg       0.84      0.84      0.84      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.927\n",
      "valid score: 0.833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_hat = rf.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = rf.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) random forest 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best score: 0.8414766110734385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 RandomForest model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.923\n",
      "valid score: 0.834\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    max_features=grid_search.best_params_['max_features'],\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_rf.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_rf.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       152\n",
      "           1       0.73      0.75      0.74       162\n",
      "           2       0.79      0.56      0.66        89\n",
      "           3       0.67      0.59      0.62        51\n",
      "           4       0.77      0.85      0.81       607\n",
      "           5       0.97      0.92      0.94       464\n",
      "           6       0.79      0.87      0.82       194\n",
      "           7       0.89      0.70      0.79       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.82      0.77      0.79      1870\n",
      "weighted avg       0.84      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\administrator\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.926\n",
      "valid score: 0.828\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_hat = xg.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = xg.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) XGBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.6}\n",
      "Best score: 0.8386236074273086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xg= xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xg, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 XGBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.923\n",
      "valid score: 0.828\n"
     ]
    }
   ],
   "source": [
    "#모델 적용                                                                                                                                                                                                                        4                                                   \n",
    "best_xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    subsample=grid_search.best_params_['subsample'],\n",
    "    colsample_bytree=grid_search.best_params_['colsample_bytree'])\n",
    "best_xg.fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_xg.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_xg.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       152\n",
      "           1       0.71      0.74      0.73       162\n",
      "           2       0.74      0.56      0.64        89\n",
      "           3       0.60      0.55      0.57        51\n",
      "           4       0.79      0.83      0.80       607\n",
      "           5       0.96      0.93      0.95       464\n",
      "           6       0.77      0.87      0.82       194\n",
      "           7       0.85      0.73      0.78       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.79      0.76      0.77      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    #상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.901\n",
      "valid score: 0.824\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "cat = CatBoostClassifier(loss_function='MultiClass', verbose=0)\n",
    "cat.fit(X_train_scaled, y_train, eval_set=(X_valid_scaled, y_valid))\n",
    "\n",
    "y_train_hat = cat.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = cat.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) CatBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
      "Best score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'iterations': [500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "cat = CatBoostClassifier(early_stopping_rounds=50, verbose=False)\n",
    "grid_search = GridSearchCV(cat, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 CatBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.919\n",
      "valid score: 0.833\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_cat = CatBoostClassifier(verbose=0,\n",
    "    iterations=grid_search.best_params_['iterations'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    depth=grid_search.best_params_['depth'],\n",
    "    l2_leaf_reg=grid_search.best_params_['l2_leaf_reg'])\n",
    "best_cat.fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_cat.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_cat.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       152\n",
      "           1       0.71      0.76      0.73       162\n",
      "           2       0.76      0.57      0.65        89\n",
      "           3       0.63      0.61      0.62        51\n",
      "           4       0.79      0.83      0.81       607\n",
      "           5       0.95      0.93      0.94       464\n",
      "           6       0.78      0.87      0.82       194\n",
      "           7       0.88      0.75      0.81       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.80      0.78      0.79      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(metrics.classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. 최종 모델 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각모델의 valid score<br/>\n",
    "\n",
    "svc = 0.839<br/>\n",
    "랜덤포레스트 = 0.834<br/>\n",
    "XGBoost = 0.828<br/>\n",
    "catBoost = 0.833"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cross validuation으로 재평가 (fold=5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 학습 데이터셋, 테스트 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 최종 학습데이터\n",
    "# X_train_scaled와 X_valid_scaled 합치기\n",
    "X_train_final = np.vstack((X_train_scaled, X_valid_scaled))\n",
    "y_train_final = np.hstack((y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc model cross validation score: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf model cross validation score: 0.843\n",
      "XGboost model cross validation score: 0.840\n",
      "CatBoost model cross validation score: 0.846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#모델별 5개의 fold로 교차검증\n",
    "svc_cv_score = cross_val_score(best_svc, X_train_final, y_train_final, cv=5) \n",
    "print(\"svc model cross validation score: %.3f\" %svc_cv_score.mean())\n",
    "\n",
    "rf_cv_score = cross_val_score(best_rf, X_train_final, y_train_final, cv=5) \n",
    "print(\"rf model cross validation score: %.3f\" %rf_cv_score.mean())\n",
    "\n",
    "xg_cv_score = cross_val_score(best_xg, X_train_final, y_train_final, cv=5) \n",
    "print(\"XGboost model cross validation score: %.3f\" %xg_cv_score.mean())\n",
    "\n",
    "cat_cv_score = cross_val_score(best_cat, X_train_final, y_train_final, cv=5) \n",
    "print(\"CatBoost model cross validation score: %.3f\" %cat_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05]일때의 catBoost 모델이 성능이 가장 높은 것을 알 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model 생성 및 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=50, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=50, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=50, gamma=0.1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bestmodel 생성\n",
    "\n",
    "best_model = SVC(C=50, gamma=0.1)\n",
    "best_model.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.925\n",
      "test score: 0.849\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = best_model.predict(X_train_final)\n",
    "train_accuracy = accuracy_score(y_train_final, y_train_hat)\n",
    "\n",
    "y_test_hat = best_model.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"test score: %.3f\" %test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       610\n",
      "           1       0.77      0.90      0.83       627\n",
      "           2       0.78      0.80      0.79       308\n",
      "           3       0.75      0.80      0.77       205\n",
      "           4       0.95      0.90      0.92      2426\n",
      "           5       0.99      0.99      0.99      1850\n",
      "           6       0.91      0.93      0.92       847\n",
      "           7       0.93      0.92      0.92       605\n",
      "\n",
      "    accuracy                           0.92      7478\n",
      "   macro avg       0.88      0.90      0.89      7478\n",
      "weighted avg       0.93      0.92      0.93      7478\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       143\n",
      "           1       0.68      0.79      0.73       157\n",
      "           2       0.60      0.65      0.62        77\n",
      "           3       0.68      0.67      0.67        57\n",
      "           4       0.82      0.81      0.82       596\n",
      "           5       0.97      0.95      0.96       470\n",
      "           6       0.91      0.85      0.88       198\n",
      "           7       0.86      0.80      0.83       172\n",
      "\n",
      "    accuracy                           0.85      1870\n",
      "   macro avg       0.80      0.81      0.81      1870\n",
      "weighted avg       0.85      0.85      0.85      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델의 precsion, recall, f1-score\n",
    "print(classification_report(y_train_final, y_train_hat))\n",
    "print(classification_report(y_test, y_test_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최종 best_모델링 결과**\n",
    "\n",
    "train score: 0.925<br>\n",
    "test score: 0.849"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
