{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. data 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 최종적으로 cluster된 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\qls05\\OneDrive\\바탕 화면\\df.csv\", encoding = 'cp949') \n",
    "#000.ipynb로부터 나온 파일임 github 링크까지 첨부하면 좋을듯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 불러온 df ->  tf-idf 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts = df['preprocessed_송출내용'].fillna('')\n",
    "vectorizer = TfidfVectorizer(max_features=30)\n",
    "vectored_df = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_df = vectored_df.todense() #vectored_df는 희소행렬이기 때문에 dense 형태로 전환.\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "df_tfidf = pd.DataFrame(dense_df, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5608, 30) y_train shape: (5608,)\n",
      "X_valid shape: (1870, 30) y_valid shape: (1870,)\n",
      "X_test shape: (1870, 30) y_test shape: (1870,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_tfidf\n",
    "y = df['label']\n",
    "\n",
    "# train : val : test = 6 : 2 : 2\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape, \"y_valid shape:\", y_valid.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) data scaling (model에 따라 scaled 된 data가 필요한 경우가 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 모델 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.863\n",
      "valid score: 0.814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = svc.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = svc.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) svc 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for문으로 탐색.** <br/>\n",
    "**1-1) C, gamma 조절**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.810093</td>\n",
       "      <td>0.783957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.759094</td>\n",
       "      <td>0.734225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.596113</td>\n",
       "      <td>0.572727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.895506</td>\n",
       "      <td>0.824064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.748039</td>\n",
       "      <td>0.724064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.603067</td>\n",
       "      <td>0.579144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.921362</td>\n",
       "      <td>0.829947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.873930</td>\n",
       "      <td>0.815508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.807061</td>\n",
       "      <td>0.778610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.747682</td>\n",
       "      <td>0.720321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.922611</td>\n",
       "      <td>0.829412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.902817</td>\n",
       "      <td>0.817112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.827568</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.787268</td>\n",
       "      <td>0.758289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C   gamma  train_accuracy  valid_accuracy\n",
       "0    0.1  0.1000        0.810093        0.783957\n",
       "1    0.1  0.0100        0.759094        0.734225\n",
       "2    0.1  0.0010        0.596113        0.572727\n",
       "3    0.1  0.0001        0.324358        0.324599\n",
       "4    1.0  0.1000        0.895506        0.824064\n",
       "5    1.0  0.0100        0.826498        0.788235\n",
       "6    1.0  0.0010        0.748039        0.724064\n",
       "7    1.0  0.0001        0.603067        0.579144\n",
       "8   10.0  0.1000        0.921362        0.829947\n",
       "9   10.0  0.0100        0.873930        0.815508\n",
       "10  10.0  0.0010        0.807061        0.778610\n",
       "11  10.0  0.0001        0.747682        0.720321\n",
       "12  50.0  0.1000        0.922611        0.829412\n",
       "13  50.0  0.0100        0.902817        0.817112\n",
       "14  50.0  0.0010        0.827568        0.788235\n",
       "15  50.0  0.0001        0.787268        0.758289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_settings = [0.1, 1, 10, 50]\n",
    "gamma_settings = [0.1, 0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for C in C_settings:\n",
    "    for gamma in gamma_settings:\n",
    "        svc = SVC(C=C, gamma=gamma, random_state=20).fit(X_train_scaled, y_train) #C, gamma 조정\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'C': C,\n",
    "                        'gamma': gamma,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-2) kernel 조절**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.808131</td>\n",
       "      <td>0.770588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.864836</td>\n",
       "      <td>0.813904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>0.882668</td>\n",
       "      <td>0.817647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>0.616043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    kernel  train_accuracy  valid_accuracy\n",
       "0   linear        0.808131        0.770588\n",
       "1      rbf        0.864836        0.813904\n",
       "2     poly        0.882668        0.817647\n",
       "3  sigmoid        0.626070        0.616043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "        svc = SVC(kernel=kernel, random_state=20).fit(X_train_scaled, y_train) #kernel 조정\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'kernel': kernel,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-3) kernel = poly로 정하고 C랑 gamma 다시 튜닝**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.901213</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.918688</td>\n",
       "      <td>0.826738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.729494</td>\n",
       "      <td>0.711765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.921719</td>\n",
       "      <td>0.830481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.846291</td>\n",
       "      <td>0.798396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.922432</td>\n",
       "      <td>0.830481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.817112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C   gamma  train_accuracy  valid_accuracy\n",
       "0    0.1  0.1000        0.901213        0.818182\n",
       "1    0.1  0.0100        0.324358        0.324599\n",
       "2    0.1  0.0010        0.324358        0.324599\n",
       "3    0.1  0.0001        0.324358        0.324599\n",
       "4    1.0  0.1000        0.918688        0.826738\n",
       "5    1.0  0.0100        0.729494        0.711765\n",
       "6    1.0  0.0010        0.324358        0.324599\n",
       "7    1.0  0.0001        0.324358        0.324599\n",
       "8   10.0  0.1000        0.921719        0.830481\n",
       "9   10.0  0.0100        0.846291        0.798396\n",
       "10  10.0  0.0010        0.324358        0.324599\n",
       "11  10.0  0.0001        0.324358        0.324599\n",
       "12  50.0  0.1000        0.922432        0.830481\n",
       "13  50.0  0.0100        0.890157        0.817112\n",
       "14  50.0  0.0010        0.324358        0.324599\n",
       "15  50.0  0.0001        0.324358        0.324599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_settings = [0.1, 1, 10, 50]\n",
    "gamma_settings = [0.1, 0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for C in C_settings:\n",
    "    for gamma in gamma_settings:\n",
    "        svc = SVC(C=C, gamma=gamma, kernel='poly', random_state=20).fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'C': C,\n",
    "                        'gamma': gamma,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적 hyperparameter:  kernel = poly, C = 50, gamma=0.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 SVC model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.922\n",
      "valid score: 0.830\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_svc = SVC(kernel='poly', C=50, gamma=0.1).fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_svc.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_svc.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       458\n",
      "           1       0.75      0.92      0.82       465\n",
      "           2       0.73      0.84      0.78       219\n",
      "           3       0.77      0.68      0.72       154\n",
      "           4       0.96      0.89      0.92      1819\n",
      "           5       0.99      0.99      0.99      1386\n",
      "           6       0.92      0.92      0.92       653\n",
      "           7       0.92      0.92      0.92       454\n",
      "\n",
      "    accuracy                           0.92      5608\n",
      "   macro avg       0.87      0.89      0.88      5608\n",
      "weighted avg       0.93      0.92      0.92      5608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 나이브베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.683\n",
      "valid score: 0.660\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = nb.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = nb.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) naive baise 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이후 gird search으로 탐색**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.01, 'fit_prior': True}\n",
      "Best score: 0.6813487533249596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.05, 0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0],\n",
    "    'fit_prior': [True, False]\n",
    "    }\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 Naive Baise model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.689\n",
      "valid score: 0.672\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_nb = MultinomialNB(alpha=grid_search.best_params_['alpha'], fit_prior=grid_search.best_params_['fit_prior'])\n",
    "best_nb.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_nb.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_nb.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       152\n",
      "           1       0.68      0.57      0.62       162\n",
      "           2       0.70      0.08      0.14        89\n",
      "           3       0.00      0.00      0.00        51\n",
      "           4       0.58      0.68      0.62       607\n",
      "           5       0.74      0.90      0.81       464\n",
      "           6       0.65      0.87      0.74       194\n",
      "           7       0.76      0.17      0.28       151\n",
      "\n",
      "    accuracy                           0.67      1870\n",
      "   macro avg       0.63      0.52      0.51      1870\n",
      "weighted avg       0.66      0.67      0.64      1870\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#상세보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.923\n",
      "valid score: 0.828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = rf.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) random forest 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "324 fits failed out of a total of 972.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "130 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "194 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\qls05\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83684108 0.83487934 0.83630651\n",
      " 0.83630613 0.83648419 0.83559226 0.83470099 0.83523584 0.83559235\n",
      " 0.83345188 0.83291703 0.83256052 0.83095586 0.83220373 0.83113431\n",
      " 0.82952841 0.83024266 0.83042034 0.82435783 0.8252489  0.82631928\n",
      " 0.82364424 0.82524881 0.82542744 0.8234658  0.82542734 0.82489239\n",
      " 0.83719825 0.83452274 0.83701933 0.83630603 0.83773234 0.83826701\n",
      " 0.83559206 0.835414   0.83612749 0.83309604 0.8314911  0.83238189\n",
      " 0.83113383 0.83327439 0.83184732 0.83059897 0.83184732 0.83095558\n",
      " 0.82489316 0.82507103 0.82400075 0.82346589 0.82382192 0.82489239\n",
      " 0.82471357 0.82328764 0.82435783        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.82489259 0.82578433 0.82560665 0.82328783 0.82417948 0.82417938\n",
      " 0.82043502 0.82168308 0.82435754 0.82328735 0.82239657 0.82400084\n",
      " 0.82168336 0.82114813 0.8231092  0.81882998 0.82079133 0.81883064\n",
      " 0.81330213 0.81615551 0.81615494 0.81776074 0.81936521 0.8163331\n",
      " 0.81758182 0.81419311 0.81579843 0.82631956 0.82614103 0.82792413\n",
      " 0.82310977 0.82221812 0.82400122 0.81989978 0.81972124 0.82293161\n",
      " 0.82400161 0.82007823 0.82114832 0.82168355 0.82096997 0.82079162\n",
      " 0.82025686 0.81847376 0.82132619 0.81365882 0.817403   0.81437241\n",
      " 0.81633367 0.81365825 0.81205378 0.81383774 0.81348057 0.81401562\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83523661 0.83701895 0.83737593\n",
      " 0.83737612 0.83684098 0.83755428 0.83398721 0.83612787 0.83559206\n",
      " 0.83059926 0.83273858 0.83309538 0.83220411 0.83273897 0.83273877\n",
      " 0.83184741 0.82935082 0.83149014 0.82364396 0.82328793 0.82346647\n",
      " 0.82524976 0.82614093 0.82596277 0.82614093 0.82453627 0.824179\n",
      " 0.83862466 0.83719796 0.83719768 0.83701933 0.83701933 0.8389804\n",
      " 0.83505711 0.83612692 0.8357707  0.83184684 0.83095586 0.83273887\n",
      " 0.8309551  0.83113373 0.83006383 0.83095548 0.82845879 0.83166859\n",
      " 0.82507084 0.82400065 0.82489268 0.82310958 0.82614064 0.82382192\n",
      " 0.82328726 0.82203958 0.82507084        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83541429 0.8343441  0.83612806 0.83791088 0.83719758 0.83577127\n",
      " 0.83666216 0.83612701 0.83630574 0.83452197 0.83113383 0.83256033\n",
      " 0.83220373 0.83113412 0.83238217 0.83024199 0.83238265 0.83059907\n",
      " 0.82667598 0.82346627 0.82507112 0.82293152 0.82489306 0.82328774\n",
      " 0.82417967 0.82453579 0.82453589 0.83452245 0.83666301 0.83612806\n",
      " 0.83773282 0.83737631 0.83701942 0.83826662 0.8379104  0.83826729\n",
      " 0.83505711 0.83220392 0.83149053 0.83273897 0.83273868 0.83380906\n",
      " 0.82792403 0.82935025 0.82899451 0.82400046 0.82293132 0.82649744\n",
      " 0.82542801 0.82471414 0.82364405 0.82221764 0.82150396 0.82346618]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best score: 0.8389803997867448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 RandomForest model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.919\n",
      "valid score: 0.830\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    max_features=grid_search.best_params_['max_features'],\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_rf.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91       152\n",
      "           1       0.71      0.73      0.72       162\n",
      "           2       0.73      0.57      0.64        89\n",
      "           3       0.66      0.49      0.56        51\n",
      "           4       0.77      0.86      0.81       607\n",
      "           5       0.97      0.92      0.95       464\n",
      "           6       0.79      0.85      0.82       194\n",
      "           7       0.91      0.70      0.79       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.81      0.75      0.77      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 99.8/99.8 MB 293.5 kB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Collecting xgboostNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 99.8/99.8 MB 606.3 kB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.922\n",
      "valid score: 0.827\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = xg.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = xg.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) XGBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best score: 0.8375539933372055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xg= xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xg, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 XGBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.910\n",
      "valid score: 0.824\n"
     ]
    }
   ],
   "source": [
    "#모델 적용                                                                                                                                                                                                                        4                                                   \n",
    "best_xgb = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    subsample=grid_search.best_params_['subsample'],\n",
    "    colsample_bytree=grid_search.best_params_['colsample_bytree'])\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_xgb.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_xgb.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       152\n",
      "           1       0.71      0.73      0.72       162\n",
      "           2       0.70      0.56      0.62        89\n",
      "           3       0.69      0.47      0.56        51\n",
      "           4       0.78      0.83      0.81       607\n",
      "           5       0.95      0.92      0.94       464\n",
      "           6       0.77      0.86      0.81       194\n",
      "           7       0.82      0.74      0.78       151\n",
      "\n",
      "    accuracy                           0.82      1870\n",
      "   macro avg       0.79      0.75      0.77      1870\n",
      "weighted avg       0.82      0.82      0.82      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\qls05\\anaconda3\\lib\\site-packages (1.2.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (2.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scipy in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2020.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (20.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (6.3.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\qls05\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.897\n",
      "valid score: 0.822\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "cat = CatBoostClassifier(loss_function='MultiClass', verbose=0)\n",
    "cat.fit(X_train, y_train, eval_set=(X_valid, y_valid))\n",
    "\n",
    "y_train_hat = cat.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = cat.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) CatBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'iterations': [500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "cat = CatBoostClassifier(early_stopping_rounds=50, verbose=False)\n",
    "grid_search = GridSearchCV(cat, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 CatBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 적용\n",
    "best_cat = CatBoostClassifier(early_stopping_rounds=50,\n",
    "    iterations=grid_search.best_params_['iterations'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    depth=grid_search.best_params_['depth'],\n",
    "    l2_leaf_reg=grid_search.best_params_['l2_leaf_reg'],\n",
    "best_cat.fit(X_train, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_cat.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_cat.predict(X_valid)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상세 보고서\n",
    "print(metrics.classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. 최종 모델 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~한 연유로 00 model이 best model로 선정되었다. 이제 최종 test를 쳐보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bestmodel 생성\n",
    "best_model = bestmodel()\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train: test = 6: 4로 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42) \n",
    "\n",
    "y_train_hat = best_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_test_hat = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"test score: %.3f\" %test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5) #5개의 fold로 교차검증\n",
    "print(\"cross validation score: %.3f\" %cv_scores)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
