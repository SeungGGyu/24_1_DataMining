{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. data 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 최종적으로 cluster된 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Administrator\\Desktop\\대학\\3학년 1학기\\데이터마이닝\\프로젝트\\new_df.csv\", encoding = 'cp949') \n",
    "#재난분류문자_클러스스터링_최종.ipynb 파일으로부터 나온 파일."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5608, 1) y_train shape: (5608,)\n",
      "X_valid shape: (1870, 1) y_valid shape: (1870,)\n",
      "X_test shape: (1870, 1) y_test shape: (1870,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 'label' 열을 삭제하고 결과를 df 변수에 저장\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# train : val : test = 6 : 2 : 2\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) \n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape, \"y_valid shape:\", y_valid.shape)\n",
    "print(\"X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 분할된 각 set ->  tf-idf 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-1) train set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터셋 벡터화\n",
    "train_texts = X_train['preprocessed_송출내용'].fillna('')\n",
    "vectorizer = TfidfVectorizer(max_features=30)\n",
    "vectored_train = vectorizer.fit_transform(train_texts).todense()\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "X_train_vectored = pd.DataFrame(vectored_train, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-2) valid set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid 데이터셋 벡터화\n",
    "valid_texts = X_valid['preprocessed_송출내용'].fillna('')\n",
    "vectored_valid = vectorizer.transform(valid_texts).todense()\n",
    "X_valid_vectored = pd.DataFrame(vectored_valid, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-3) test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터셋 벡터화\n",
    "test_texts = X_test['preprocessed_송출내용'].fillna('')\n",
    "vectored_test = vectorizer.transform(test_texts).todense()\n",
    "X_test_vectored = pd.DataFrame(vectored_test, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) set별 data scaling (model에 따라 scaled 된 data가 필요한 경우가 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vectored)\n",
    "X_valid_scaled = scaler.transform(X_valid_vectored)\n",
    "X_test_scaled = scaler.transform(X_test_vectored)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 모델 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.870\n",
      "valid score: 0.817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_hat = svc.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = svc.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1) svc 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**for문으로 탐색.** <br/>\n",
    "**1-1) C, gamma 조절**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.809201</td>\n",
       "      <td>0.783957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.756419</td>\n",
       "      <td>0.731551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.600036</td>\n",
       "      <td>0.574866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.324358</td>\n",
       "      <td>0.324599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.901213</td>\n",
       "      <td>0.832086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.829886</td>\n",
       "      <td>0.792513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.748395</td>\n",
       "      <td>0.725668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.604315</td>\n",
       "      <td>0.577540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.925999</td>\n",
       "      <td>0.839037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.880350</td>\n",
       "      <td>0.817112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.803495</td>\n",
       "      <td>0.770053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.746969</td>\n",
       "      <td>0.721390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.926890</td>\n",
       "      <td>0.839037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.909058</td>\n",
       "      <td>0.824064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.827746</td>\n",
       "      <td>0.782888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.783167</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C   gamma  train_accuracy  valid_accuracy\n",
       "0    0.1  0.1000        0.809201        0.783957\n",
       "1    0.1  0.0100        0.756419        0.731551\n",
       "2    0.1  0.0010        0.600036        0.574866\n",
       "3    0.1  0.0001        0.324358        0.324599\n",
       "4    1.0  0.1000        0.901213        0.832086\n",
       "5    1.0  0.0100        0.829886        0.792513\n",
       "6    1.0  0.0010        0.748395        0.725668\n",
       "7    1.0  0.0001        0.604315        0.577540\n",
       "8   10.0  0.1000        0.925999        0.839037\n",
       "9   10.0  0.0100        0.880350        0.817112\n",
       "10  10.0  0.0010        0.803495        0.770053\n",
       "11  10.0  0.0001        0.746969        0.721390\n",
       "12  50.0  0.1000        0.926890        0.839037\n",
       "13  50.0  0.0100        0.909058        0.824064\n",
       "14  50.0  0.0010        0.827746        0.782888\n",
       "15  50.0  0.0001        0.783167        0.759358"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_settings = [0.1, 1, 10, 50]\n",
    "gamma_settings = [0.1, 0.01, 0.001, 0.0001]\n",
    "results = []\n",
    "\n",
    "for C in C_settings:\n",
    "    for gamma in gamma_settings:\n",
    "        svc = SVC(C=C, gamma=gamma, random_state=20).fit(X_train_scaled, y_train) #C, gamma 조정\n",
    "\n",
    "        y_train_hat = svc.predict(X_train_scaled)\n",
    "        y_valid_hat =svc.predict(X_valid_scaled)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "        \n",
    "\n",
    "        results.append({'C': C,\n",
    "                        'gamma': gamma,\n",
    "                        'train_accuracy': train_accuracy,\n",
    "                        'valid_accuracy': valid_accuracy})\n",
    "\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적 hyperparameter:  kernel = poly, C = 50.0, gamma=0.1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 SVC model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.927\n",
      "valid score: 0.839\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_svc = SVC(C=50, gamma=0.1).fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_svc.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_svc.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       152\n",
      "           1       0.73      0.75      0.74       162\n",
      "           2       0.64      0.61      0.62        89\n",
      "           3       0.70      0.59      0.64        51\n",
      "           4       0.81      0.83      0.82       607\n",
      "           5       0.97      0.95      0.96       464\n",
      "           6       0.77      0.86      0.81       194\n",
      "           7       0.84      0.75      0.79       151\n",
      "\n",
      "    accuracy                           0.84      1870\n",
      "   macro avg       0.80      0.78      0.79      1870\n",
      "weighted avg       0.84      0.84      0.84      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.927\n",
      "valid score: 0.833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_hat = rf.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = rf.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) random forest 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best score: 0.8414766110734385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 RandomForest model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.923\n",
      "valid score: 0.834\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    max_features=grid_search.best_params_['max_features'],\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "    min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_rf.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_rf.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       152\n",
      "           1       0.73      0.75      0.74       162\n",
      "           2       0.79      0.56      0.66        89\n",
      "           3       0.67      0.59      0.62        51\n",
      "           4       0.77      0.85      0.81       607\n",
      "           5       0.97      0.92      0.94       464\n",
      "           6       0.79      0.87      0.82       194\n",
      "           7       0.89      0.70      0.79       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.82      0.77      0.79      1870\n",
      "weighted avg       0.84      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\administrator\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.926\n",
      "valid score: 0.828\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_train_hat = xg.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = xg.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) XGBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.6}\n",
      "Best score: 0.8386236074273086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xg= xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xg, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 최적의 파라미터와 최고의 점수 출력\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 XGBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.923\n",
      "valid score: 0.828\n"
     ]
    }
   ],
   "source": [
    "#모델 적용                                                                                                                                                                                                                        4                                                   \n",
    "best_xg = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss',\n",
    "    max_depth=grid_search.best_params_['max_depth'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    n_estimators=grid_search.best_params_['n_estimators'],\n",
    "    subsample=grid_search.best_params_['subsample'],\n",
    "    colsample_bytree=grid_search.best_params_['colsample_bytree'])\n",
    "best_xg.fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_xg.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_xg.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       152\n",
      "           1       0.71      0.74      0.73       162\n",
      "           2       0.74      0.56      0.64        89\n",
      "           3       0.60      0.55      0.57        51\n",
      "           4       0.79      0.83      0.80       607\n",
      "           5       0.96      0.93      0.95       464\n",
      "           6       0.77      0.87      0.82       194\n",
      "           7       0.85      0.73      0.78       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.79      0.76      0.77      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    #상세 보고서\n",
    "print(classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.901\n",
      "valid score: 0.824\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "cat = CatBoostClassifier(loss_function='MultiClass', verbose=0)\n",
    "cat.fit(X_train_scaled, y_train, eval_set=(X_valid_scaled, y_valid))\n",
    "\n",
    "y_train_hat = cat.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = cat.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) CatBoost 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**gird search로 조정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'depth': 10, 'iterations': 500, 'l2_leaf_reg': 1, 'learning_rate': 0.05}\n",
      "Best score: 0.84\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'iterations': [500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 10],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "cat = CatBoostClassifier(early_stopping_rounds=50, verbose=False)\n",
    "grid_search = GridSearchCV(cat, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 최적의 hyperparameter를 적용한 CatBoost model 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.919\n",
      "valid score: 0.833\n"
     ]
    }
   ],
   "source": [
    "#모델 적용\n",
    "best_cat = CatBoostClassifier(verbose=0,\n",
    "    iterations=grid_search.best_params_['iterations'],\n",
    "    learning_rate=grid_search.best_params_['learning_rate'],\n",
    "    depth=grid_search.best_params_['depth'],\n",
    "    l2_leaf_reg=grid_search.best_params_['l2_leaf_reg'])\n",
    "best_cat.fit(X_train_scaled, y_train)\n",
    "\n",
    "#모델 평가\n",
    "y_train_hat = best_cat.predict(X_train_scaled)\n",
    "train_accuracy = accuracy_score(y_train, y_train_hat)\n",
    "\n",
    "y_valid_hat = best_cat.predict(X_valid_scaled)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"valid score: %.3f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       152\n",
      "           1       0.71      0.76      0.73       162\n",
      "           2       0.76      0.57      0.65        89\n",
      "           3       0.63      0.61      0.62        51\n",
      "           4       0.79      0.83      0.81       607\n",
      "           5       0.95      0.93      0.94       464\n",
      "           6       0.78      0.87      0.82       194\n",
      "           7       0.88      0.75      0.81       151\n",
      "\n",
      "    accuracy                           0.83      1870\n",
      "   macro avg       0.80      0.78      0.79      1870\n",
      "weighted avg       0.83      0.83      0.83      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#상세 보고서\n",
    "print(metrics.classification_report(y_valid, y_valid_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. 최종 모델 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각모델의 valid score<br/><br/>\n",
    "\n",
    "svc = 0.830<br/>\n",
    "나이브베이즈 = 0.672<br/>\n",
    "랜덤포레스트 = 0.830<br/>\n",
    "XGBoost = 0.824<br/>\n",
    "catBoost = 0.828 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**나이브 베이즈를 제외한 4가지 모델의 성능이0.01정도의 차이를 보이므로 cross validuation으로 재평가 (fold=5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 학습 데이터셋, 테스트 데이터셋\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 최종 학습데이터\n",
    "# X_train_scaled와 X_valid_scaled 합치기\n",
    "X_train_final = np.vstack((X_train_scaled, X_valid_scaled))\n",
    "y_train_final = np.hstack((y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc model cross validation score: 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf model cross validation score: 0.843\n",
      "XGboost model cross validation score: 0.840\n",
      "CatBoost model cross validation score: 0.846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#모델별 5개의 fold로 교차검증\n",
    "svc_cv_score = cross_val_score(best_svc, X_train_final, y_train_final, cv=5) \n",
    "print(\"svc model cross validation score: %.3f\" %svc_cv_score.mean())\n",
    "\n",
    "rf_cv_score = cross_val_score(best_rf, X_train_final, y_train_final, cv=5) \n",
    "print(\"rf model cross validation score: %.3f\" %rf_cv_score.mean())\n",
    "\n",
    "xg_cv_score = cross_val_score(best_xg, X_train_final, y_train_final, cv=5) \n",
    "print(\"XGboost model cross validation score: %.3f\" %xg_cv_score.mean())\n",
    "\n",
    "cat_cv_score = cross_val_score(best_cat, X_train_final, y_train_final, cv=5) \n",
    "print(\"CatBoost model cross validation score: %.3f\" %cat_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['depth': 10, 'iterations': 500, 'l2_leaf_reg': 3, 'learning_rate': 0.05]일때의 catBoost 모델이 성능이 가장 높은 것을 알 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best model 생성 및 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9234594\ttotal: 1.23s\tremaining: 10m 11s\n",
      "1:\tlearn: 1.7953078\ttotal: 2.4s\tremaining: 9m 58s\n",
      "2:\tlearn: 1.6883976\ttotal: 3.65s\tremaining: 10m 4s\n",
      "3:\tlearn: 1.5959772\ttotal: 5.06s\tremaining: 10m 27s\n",
      "4:\tlearn: 1.5188433\ttotal: 6.81s\tremaining: 11m 14s\n",
      "5:\tlearn: 1.4509323\ttotal: 8.31s\tremaining: 11m 24s\n",
      "6:\tlearn: 1.3911064\ttotal: 9.47s\tremaining: 11m 6s\n",
      "7:\tlearn: 1.3371277\ttotal: 10.4s\tremaining: 10m 42s\n",
      "8:\tlearn: 1.2884664\ttotal: 11.4s\tremaining: 10m 23s\n",
      "9:\tlearn: 1.2425742\ttotal: 12.7s\tremaining: 10m 21s\n",
      "10:\tlearn: 1.2003470\ttotal: 13.8s\tremaining: 10m 15s\n",
      "11:\tlearn: 1.1625503\ttotal: 15s\tremaining: 10m 11s\n",
      "12:\tlearn: 1.1276101\ttotal: 16.3s\tremaining: 10m 10s\n",
      "13:\tlearn: 1.0966410\ttotal: 17.4s\tremaining: 10m 3s\n",
      "14:\tlearn: 1.0659643\ttotal: 18.4s\tremaining: 9m 54s\n",
      "15:\tlearn: 1.0380744\ttotal: 19.4s\tremaining: 9m 46s\n",
      "16:\tlearn: 1.0109761\ttotal: 20.4s\tremaining: 9m 38s\n",
      "17:\tlearn: 0.9864258\ttotal: 21.4s\tremaining: 9m 31s\n",
      "18:\tlearn: 0.9630304\ttotal: 22.4s\tremaining: 9m 27s\n",
      "19:\tlearn: 0.9419452\ttotal: 23.4s\tremaining: 9m 20s\n",
      "20:\tlearn: 0.9221137\ttotal: 24.3s\tremaining: 9m 14s\n",
      "21:\tlearn: 0.9023599\ttotal: 25.3s\tremaining: 9m 9s\n",
      "22:\tlearn: 0.8852270\ttotal: 26.3s\tremaining: 9m 5s\n",
      "23:\tlearn: 0.8679655\ttotal: 27.3s\tremaining: 9m 1s\n",
      "24:\tlearn: 0.8514895\ttotal: 28.5s\tremaining: 9m\n",
      "25:\tlearn: 0.8357308\ttotal: 29.7s\tremaining: 9m\n",
      "26:\tlearn: 0.8214882\ttotal: 30.8s\tremaining: 8m 59s\n",
      "27:\tlearn: 0.8069631\ttotal: 32s\tremaining: 8m 58s\n",
      "28:\tlearn: 0.7943624\ttotal: 33.2s\tremaining: 8m 58s\n",
      "29:\tlearn: 0.7818557\ttotal: 34.2s\tremaining: 8m 55s\n",
      "30:\tlearn: 0.7710379\ttotal: 35.1s\tremaining: 8m 51s\n",
      "31:\tlearn: 0.7598676\ttotal: 36.1s\tremaining: 8m 47s\n",
      "32:\tlearn: 0.7489878\ttotal: 37s\tremaining: 8m 43s\n",
      "33:\tlearn: 0.7382846\ttotal: 38s\tremaining: 8m 40s\n",
      "34:\tlearn: 0.7290125\ttotal: 39s\tremaining: 8m 37s\n",
      "35:\tlearn: 0.7201504\ttotal: 39.9s\tremaining: 8m 34s\n",
      "36:\tlearn: 0.7114092\ttotal: 40.9s\tremaining: 8m 31s\n",
      "37:\tlearn: 0.7033101\ttotal: 41.9s\tremaining: 8m 28s\n",
      "38:\tlearn: 0.6954341\ttotal: 42.9s\tremaining: 8m 26s\n",
      "39:\tlearn: 0.6882803\ttotal: 43.9s\tremaining: 8m 25s\n",
      "40:\tlearn: 0.6809877\ttotal: 45.3s\tremaining: 8m 26s\n",
      "41:\tlearn: 0.6741183\ttotal: 46.5s\tremaining: 8m 26s\n",
      "42:\tlearn: 0.6672854\ttotal: 47.6s\tremaining: 8m 26s\n",
      "43:\tlearn: 0.6608104\ttotal: 48.8s\tremaining: 8m 25s\n",
      "44:\tlearn: 0.6542761\ttotal: 49.9s\tremaining: 8m 24s\n",
      "45:\tlearn: 0.6481456\ttotal: 50.9s\tremaining: 8m 22s\n",
      "46:\tlearn: 0.6435396\ttotal: 51.9s\tremaining: 8m 19s\n",
      "47:\tlearn: 0.6379836\ttotal: 52.9s\tremaining: 8m 17s\n",
      "48:\tlearn: 0.6330040\ttotal: 53.9s\tremaining: 8m 15s\n",
      "49:\tlearn: 0.6281177\ttotal: 54.8s\tremaining: 8m 13s\n",
      "50:\tlearn: 0.6228971\ttotal: 55.8s\tremaining: 8m 11s\n",
      "51:\tlearn: 0.6176444\ttotal: 56.8s\tremaining: 8m 9s\n",
      "52:\tlearn: 0.6129044\ttotal: 57.8s\tremaining: 8m 7s\n",
      "53:\tlearn: 0.6089207\ttotal: 58.8s\tremaining: 8m 5s\n",
      "54:\tlearn: 0.6040939\ttotal: 59.8s\tremaining: 8m 4s\n",
      "55:\tlearn: 0.6003199\ttotal: 1m 1s\tremaining: 8m 3s\n",
      "56:\tlearn: 0.5957747\ttotal: 1m 2s\tremaining: 8m 3s\n",
      "57:\tlearn: 0.5919327\ttotal: 1m 3s\tremaining: 8m 2s\n",
      "58:\tlearn: 0.5874101\ttotal: 1m 4s\tremaining: 8m 2s\n",
      "59:\tlearn: 0.5835476\ttotal: 1m 5s\tremaining: 8m 1s\n",
      "60:\tlearn: 0.5806413\ttotal: 1m 6s\tremaining: 7m 59s\n",
      "61:\tlearn: 0.5770377\ttotal: 1m 7s\tremaining: 7m 58s\n",
      "62:\tlearn: 0.5734098\ttotal: 1m 8s\tremaining: 7m 56s\n",
      "63:\tlearn: 0.5693955\ttotal: 1m 9s\tremaining: 7m 54s\n",
      "64:\tlearn: 0.5656115\ttotal: 1m 10s\tremaining: 7m 52s\n",
      "65:\tlearn: 0.5631328\ttotal: 1m 11s\tremaining: 7m 50s\n",
      "66:\tlearn: 0.5599174\ttotal: 1m 12s\tremaining: 7m 49s\n",
      "67:\tlearn: 0.5576296\ttotal: 1m 13s\tremaining: 7m 47s\n",
      "68:\tlearn: 0.5546759\ttotal: 1m 14s\tremaining: 7m 45s\n",
      "69:\tlearn: 0.5519436\ttotal: 1m 16s\tremaining: 7m 46s\n",
      "70:\tlearn: 0.5499714\ttotal: 1m 17s\tremaining: 7m 48s\n",
      "71:\tlearn: 0.5479334\ttotal: 1m 18s\tremaining: 7m 49s\n",
      "72:\tlearn: 0.5452653\ttotal: 1m 20s\tremaining: 7m 50s\n",
      "73:\tlearn: 0.5430366\ttotal: 1m 21s\tremaining: 7m 51s\n",
      "74:\tlearn: 0.5408713\ttotal: 1m 24s\tremaining: 7m 58s\n",
      "75:\tlearn: 0.5381179\ttotal: 1m 25s\tremaining: 7m 59s\n",
      "76:\tlearn: 0.5359182\ttotal: 1m 27s\tremaining: 8m\n",
      "77:\tlearn: 0.5340544\ttotal: 1m 28s\tremaining: 7m 59s\n",
      "78:\tlearn: 0.5326427\ttotal: 1m 29s\tremaining: 7m 58s\n",
      "79:\tlearn: 0.5310469\ttotal: 1m 31s\tremaining: 7m 59s\n",
      "80:\tlearn: 0.5289372\ttotal: 1m 33s\tremaining: 8m 1s\n",
      "81:\tlearn: 0.5269515\ttotal: 1m 34s\tremaining: 8m 3s\n",
      "82:\tlearn: 0.5249627\ttotal: 1m 36s\tremaining: 8m 3s\n",
      "83:\tlearn: 0.5228122\ttotal: 1m 37s\tremaining: 8m 4s\n",
      "84:\tlearn: 0.5204673\ttotal: 1m 39s\tremaining: 8m 4s\n",
      "85:\tlearn: 0.5186917\ttotal: 1m 40s\tremaining: 8m 3s\n",
      "86:\tlearn: 0.5169868\ttotal: 1m 41s\tremaining: 8m 1s\n",
      "87:\tlearn: 0.5153853\ttotal: 1m 42s\tremaining: 8m 1s\n",
      "88:\tlearn: 0.5125936\ttotal: 1m 43s\tremaining: 7m 59s\n",
      "89:\tlearn: 0.5105465\ttotal: 1m 44s\tremaining: 7m 58s\n",
      "90:\tlearn: 0.5090317\ttotal: 1m 46s\tremaining: 7m 58s\n",
      "91:\tlearn: 0.5071770\ttotal: 1m 47s\tremaining: 7m 57s\n",
      "92:\tlearn: 0.5052091\ttotal: 1m 48s\tremaining: 7m 56s\n",
      "93:\tlearn: 0.5033531\ttotal: 1m 50s\tremaining: 7m 55s\n",
      "94:\tlearn: 0.5018719\ttotal: 1m 51s\tremaining: 7m 55s\n",
      "95:\tlearn: 0.5003703\ttotal: 1m 53s\tremaining: 7m 57s\n",
      "96:\tlearn: 0.4988135\ttotal: 1m 54s\tremaining: 7m 56s\n",
      "97:\tlearn: 0.4974691\ttotal: 1m 56s\tremaining: 7m 56s\n",
      "98:\tlearn: 0.4959127\ttotal: 1m 57s\tremaining: 7m 57s\n",
      "99:\tlearn: 0.4943613\ttotal: 1m 59s\tremaining: 7m 57s\n",
      "100:\tlearn: 0.4930788\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "101:\tlearn: 0.4911850\ttotal: 2m 2s\tremaining: 7m 59s\n",
      "102:\tlearn: 0.4894366\ttotal: 2m 4s\tremaining: 8m\n",
      "103:\tlearn: 0.4882460\ttotal: 2m 6s\tremaining: 8m 2s\n",
      "104:\tlearn: 0.4868950\ttotal: 2m 9s\tremaining: 8m 7s\n",
      "105:\tlearn: 0.4855648\ttotal: 2m 14s\tremaining: 8m 19s\n",
      "106:\tlearn: 0.4843613\ttotal: 2m 17s\tremaining: 8m 23s\n",
      "107:\tlearn: 0.4831038\ttotal: 2m 18s\tremaining: 8m 23s\n",
      "108:\tlearn: 0.4816219\ttotal: 2m 20s\tremaining: 8m 22s\n",
      "109:\tlearn: 0.4802966\ttotal: 2m 21s\tremaining: 8m 21s\n",
      "110:\tlearn: 0.4793658\ttotal: 2m 23s\tremaining: 8m 21s\n",
      "111:\tlearn: 0.4780851\ttotal: 2m 24s\tremaining: 8m 20s\n",
      "112:\tlearn: 0.4765544\ttotal: 2m 26s\tremaining: 8m 20s\n",
      "113:\tlearn: 0.4755807\ttotal: 2m 27s\tremaining: 8m 19s\n",
      "114:\tlearn: 0.4742272\ttotal: 2m 28s\tremaining: 8m 16s\n",
      "115:\tlearn: 0.4726279\ttotal: 2m 29s\tremaining: 8m 14s\n",
      "116:\tlearn: 0.4709476\ttotal: 2m 30s\tremaining: 8m 12s\n",
      "117:\tlearn: 0.4700417\ttotal: 2m 31s\tremaining: 8m 10s\n",
      "118:\tlearn: 0.4686485\ttotal: 2m 32s\tremaining: 8m 8s\n",
      "119:\tlearn: 0.4676858\ttotal: 2m 33s\tremaining: 8m 6s\n",
      "120:\tlearn: 0.4668939\ttotal: 2m 34s\tremaining: 8m 5s\n",
      "121:\tlearn: 0.4661840\ttotal: 2m 35s\tremaining: 8m 3s\n",
      "122:\tlearn: 0.4655023\ttotal: 2m 37s\tremaining: 8m 1s\n",
      "123:\tlearn: 0.4646278\ttotal: 2m 39s\tremaining: 8m 2s\n",
      "124:\tlearn: 0.4635734\ttotal: 2m 41s\tremaining: 8m 3s\n",
      "125:\tlearn: 0.4624591\ttotal: 2m 42s\tremaining: 8m 3s\n",
      "126:\tlearn: 0.4615491\ttotal: 2m 45s\tremaining: 8m 4s\n",
      "127:\tlearn: 0.4606979\ttotal: 2m 46s\tremaining: 8m 3s\n",
      "128:\tlearn: 0.4598868\ttotal: 2m 47s\tremaining: 8m 1s\n",
      "129:\tlearn: 0.4587824\ttotal: 2m 48s\tremaining: 7m 59s\n",
      "130:\tlearn: 0.4575592\ttotal: 2m 49s\tremaining: 7m 57s\n",
      "131:\tlearn: 0.4567213\ttotal: 2m 50s\tremaining: 7m 55s\n",
      "132:\tlearn: 0.4556594\ttotal: 2m 51s\tremaining: 7m 53s\n",
      "133:\tlearn: 0.4548394\ttotal: 2m 52s\tremaining: 7m 51s\n",
      "134:\tlearn: 0.4535967\ttotal: 2m 53s\tremaining: 7m 49s\n",
      "135:\tlearn: 0.4525351\ttotal: 2m 54s\tremaining: 7m 48s\n",
      "136:\tlearn: 0.4516304\ttotal: 2m 56s\tremaining: 7m 47s\n",
      "137:\tlearn: 0.4508678\ttotal: 2m 57s\tremaining: 7m 45s\n",
      "138:\tlearn: 0.4498372\ttotal: 2m 58s\tremaining: 7m 44s\n",
      "139:\tlearn: 0.4491505\ttotal: 3m\tremaining: 7m 42s\n",
      "140:\tlearn: 0.4478964\ttotal: 3m 1s\tremaining: 7m 41s\n",
      "141:\tlearn: 0.4472662\ttotal: 3m 2s\tremaining: 7m 40s\n",
      "142:\tlearn: 0.4466873\ttotal: 3m 3s\tremaining: 7m 38s\n",
      "143:\tlearn: 0.4458875\ttotal: 3m 5s\tremaining: 7m 38s\n",
      "144:\tlearn: 0.4449576\ttotal: 3m 6s\tremaining: 7m 36s\n",
      "145:\tlearn: 0.4438841\ttotal: 3m 7s\tremaining: 7m 34s\n",
      "146:\tlearn: 0.4430770\ttotal: 3m 8s\tremaining: 7m 32s\n",
      "147:\tlearn: 0.4421791\ttotal: 3m 9s\tremaining: 7m 31s\n",
      "148:\tlearn: 0.4412923\ttotal: 3m 10s\tremaining: 7m 29s\n",
      "149:\tlearn: 0.4407246\ttotal: 3m 12s\tremaining: 7m 28s\n",
      "150:\tlearn: 0.4399275\ttotal: 3m 13s\tremaining: 7m 27s\n",
      "151:\tlearn: 0.4393585\ttotal: 3m 15s\tremaining: 7m 26s\n",
      "152:\tlearn: 0.4386473\ttotal: 3m 16s\tremaining: 7m 24s\n",
      "153:\tlearn: 0.4379632\ttotal: 3m 17s\tremaining: 7m 22s\n",
      "154:\tlearn: 0.4371848\ttotal: 3m 18s\tremaining: 7m 20s\n",
      "155:\tlearn: 0.4363102\ttotal: 3m 19s\tremaining: 7m 18s\n",
      "156:\tlearn: 0.4356808\ttotal: 3m 20s\tremaining: 7m 17s\n",
      "157:\tlearn: 0.4349171\ttotal: 3m 21s\tremaining: 7m 15s\n",
      "158:\tlearn: 0.4340011\ttotal: 3m 21s\tremaining: 7m 13s\n",
      "159:\tlearn: 0.4332574\ttotal: 3m 22s\tremaining: 7m 11s\n",
      "160:\tlearn: 0.4325105\ttotal: 3m 24s\tremaining: 7m 9s\n",
      "161:\tlearn: 0.4316085\ttotal: 3m 25s\tremaining: 7m 8s\n",
      "162:\tlearn: 0.4308706\ttotal: 3m 26s\tremaining: 7m 6s\n",
      "163:\tlearn: 0.4302002\ttotal: 3m 27s\tremaining: 7m 5s\n",
      "164:\tlearn: 0.4296599\ttotal: 3m 28s\tremaining: 7m 3s\n",
      "165:\tlearn: 0.4290757\ttotal: 3m 29s\tremaining: 7m 2s\n",
      "166:\tlearn: 0.4284769\ttotal: 3m 30s\tremaining: 7m\n",
      "167:\tlearn: 0.4276840\ttotal: 3m 31s\tremaining: 6m 58s\n",
      "168:\tlearn: 0.4270056\ttotal: 3m 32s\tremaining: 6m 56s\n",
      "169:\tlearn: 0.4263564\ttotal: 3m 33s\tremaining: 6m 54s\n",
      "170:\tlearn: 0.4256773\ttotal: 3m 34s\tremaining: 6m 53s\n",
      "171:\tlearn: 0.4249659\ttotal: 3m 35s\tremaining: 6m 51s\n",
      "172:\tlearn: 0.4244884\ttotal: 3m 36s\tremaining: 6m 49s\n",
      "173:\tlearn: 0.4237219\ttotal: 3m 37s\tremaining: 6m 47s\n",
      "174:\tlearn: 0.4231932\ttotal: 3m 38s\tremaining: 6m 46s\n",
      "175:\tlearn: 0.4228809\ttotal: 3m 39s\tremaining: 6m 44s\n",
      "176:\tlearn: 0.4225100\ttotal: 3m 41s\tremaining: 6m 43s\n",
      "177:\tlearn: 0.4220028\ttotal: 3m 42s\tremaining: 6m 42s\n",
      "178:\tlearn: 0.4214263\ttotal: 3m 43s\tremaining: 6m 40s\n",
      "179:\tlearn: 0.4208541\ttotal: 3m 44s\tremaining: 6m 39s\n",
      "180:\tlearn: 0.4203068\ttotal: 3m 45s\tremaining: 6m 37s\n",
      "181:\tlearn: 0.4198848\ttotal: 3m 46s\tremaining: 6m 36s\n",
      "182:\tlearn: 0.4192604\ttotal: 3m 47s\tremaining: 6m 34s\n",
      "183:\tlearn: 0.4184626\ttotal: 3m 48s\tremaining: 6m 32s\n",
      "184:\tlearn: 0.4177484\ttotal: 3m 49s\tremaining: 6m 31s\n",
      "185:\tlearn: 0.4172524\ttotal: 3m 51s\tremaining: 6m 30s\n",
      "186:\tlearn: 0.4165538\ttotal: 3m 52s\tremaining: 6m 28s\n",
      "187:\tlearn: 0.4159325\ttotal: 3m 53s\tremaining: 6m 27s\n",
      "188:\tlearn: 0.4155795\ttotal: 3m 54s\tremaining: 6m 25s\n",
      "189:\tlearn: 0.4149080\ttotal: 3m 55s\tremaining: 6m 24s\n",
      "190:\tlearn: 0.4141037\ttotal: 3m 56s\tremaining: 6m 22s\n",
      "191:\tlearn: 0.4136587\ttotal: 3m 57s\tremaining: 6m 21s\n",
      "192:\tlearn: 0.4131718\ttotal: 3m 59s\tremaining: 6m 20s\n",
      "193:\tlearn: 0.4123616\ttotal: 4m\tremaining: 6m 19s\n",
      "194:\tlearn: 0.4120301\ttotal: 4m 1s\tremaining: 6m 18s\n",
      "195:\tlearn: 0.4113116\ttotal: 4m 3s\tremaining: 6m 17s\n",
      "196:\tlearn: 0.4107543\ttotal: 4m 4s\tremaining: 6m 15s\n",
      "197:\tlearn: 0.4103147\ttotal: 4m 5s\tremaining: 6m 14s\n",
      "198:\tlearn: 0.4099284\ttotal: 4m 6s\tremaining: 6m 12s\n",
      "199:\tlearn: 0.4092790\ttotal: 4m 7s\tremaining: 6m 11s\n",
      "200:\tlearn: 0.4087922\ttotal: 4m 8s\tremaining: 6m 9s\n",
      "201:\tlearn: 0.4082323\ttotal: 4m 10s\tremaining: 6m 8s\n",
      "202:\tlearn: 0.4077630\ttotal: 4m 11s\tremaining: 6m 8s\n",
      "203:\tlearn: 0.4073437\ttotal: 4m 13s\tremaining: 6m 7s\n",
      "204:\tlearn: 0.4070564\ttotal: 4m 14s\tremaining: 6m 6s\n",
      "205:\tlearn: 0.4063732\ttotal: 4m 15s\tremaining: 6m 5s\n",
      "206:\tlearn: 0.4058875\ttotal: 4m 17s\tremaining: 6m 4s\n",
      "207:\tlearn: 0.4055416\ttotal: 4m 18s\tremaining: 6m 2s\n",
      "208:\tlearn: 0.4053298\ttotal: 4m 19s\tremaining: 6m 1s\n",
      "209:\tlearn: 0.4047873\ttotal: 4m 20s\tremaining: 5m 59s\n",
      "210:\tlearn: 0.4042634\ttotal: 4m 21s\tremaining: 5m 57s\n",
      "211:\tlearn: 0.4040208\ttotal: 4m 22s\tremaining: 5m 56s\n",
      "212:\tlearn: 0.4035409\ttotal: 4m 23s\tremaining: 5m 55s\n",
      "213:\tlearn: 0.4031892\ttotal: 4m 24s\tremaining: 5m 53s\n",
      "214:\tlearn: 0.4028722\ttotal: 4m 25s\tremaining: 5m 52s\n",
      "215:\tlearn: 0.4023756\ttotal: 4m 26s\tremaining: 5m 50s\n",
      "216:\tlearn: 0.4019196\ttotal: 4m 27s\tremaining: 5m 48s\n",
      "217:\tlearn: 0.4015170\ttotal: 4m 28s\tremaining: 5m 47s\n",
      "218:\tlearn: 0.4012510\ttotal: 4m 29s\tremaining: 5m 46s\n",
      "219:\tlearn: 0.4009882\ttotal: 4m 30s\tremaining: 5m 44s\n",
      "220:\tlearn: 0.4007416\ttotal: 4m 32s\tremaining: 5m 43s\n",
      "221:\tlearn: 0.4000572\ttotal: 4m 33s\tremaining: 5m 42s\n",
      "222:\tlearn: 0.3998894\ttotal: 4m 34s\tremaining: 5m 40s\n",
      "223:\tlearn: 0.3996663\ttotal: 4m 35s\tremaining: 5m 39s\n",
      "224:\tlearn: 0.3991613\ttotal: 4m 36s\tremaining: 5m 38s\n",
      "225:\tlearn: 0.3988250\ttotal: 4m 37s\tremaining: 5m 36s\n",
      "226:\tlearn: 0.3983083\ttotal: 4m 38s\tremaining: 5m 35s\n",
      "227:\tlearn: 0.3979236\ttotal: 4m 39s\tremaining: 5m 33s\n",
      "228:\tlearn: 0.3978625\ttotal: 4m 40s\tremaining: 5m 32s\n",
      "229:\tlearn: 0.3973041\ttotal: 4m 41s\tremaining: 5m 30s\n",
      "230:\tlearn: 0.3971246\ttotal: 4m 42s\tremaining: 5m 29s\n",
      "231:\tlearn: 0.3966267\ttotal: 4m 43s\tremaining: 5m 27s\n",
      "232:\tlearn: 0.3960638\ttotal: 4m 44s\tremaining: 5m 26s\n",
      "233:\tlearn: 0.3957726\ttotal: 4m 45s\tremaining: 5m 24s\n",
      "234:\tlearn: 0.3956227\ttotal: 4m 46s\tremaining: 5m 23s\n",
      "235:\tlearn: 0.3950331\ttotal: 4m 48s\tremaining: 5m 22s\n",
      "236:\tlearn: 0.3941886\ttotal: 4m 49s\tremaining: 5m 20s\n",
      "237:\tlearn: 0.3937711\ttotal: 4m 50s\tremaining: 5m 19s\n",
      "238:\tlearn: 0.3934484\ttotal: 4m 51s\tremaining: 5m 18s\n",
      "239:\tlearn: 0.3926864\ttotal: 4m 52s\tremaining: 5m 16s\n",
      "240:\tlearn: 0.3925412\ttotal: 4m 53s\tremaining: 5m 15s\n",
      "241:\tlearn: 0.3922859\ttotal: 4m 54s\tremaining: 5m 13s\n",
      "242:\tlearn: 0.3918956\ttotal: 4m 55s\tremaining: 5m 12s\n",
      "243:\tlearn: 0.3915221\ttotal: 4m 56s\tremaining: 5m 10s\n",
      "244:\tlearn: 0.3912961\ttotal: 4m 57s\tremaining: 5m 9s\n",
      "245:\tlearn: 0.3907389\ttotal: 4m 58s\tremaining: 5m 8s\n",
      "246:\tlearn: 0.3903471\ttotal: 4m 59s\tremaining: 5m 6s\n",
      "247:\tlearn: 0.3898747\ttotal: 5m\tremaining: 5m 5s\n",
      "248:\tlearn: 0.3891562\ttotal: 5m 1s\tremaining: 5m 4s\n",
      "249:\tlearn: 0.3887853\ttotal: 5m 3s\tremaining: 5m 3s\n",
      "250:\tlearn: 0.3884029\ttotal: 5m 4s\tremaining: 5m 1s\n",
      "251:\tlearn: 0.3879591\ttotal: 5m 5s\tremaining: 5m\n",
      "252:\tlearn: 0.3876846\ttotal: 5m 6s\tremaining: 4m 59s\n",
      "253:\tlearn: 0.3874262\ttotal: 5m 7s\tremaining: 4m 58s\n",
      "254:\tlearn: 0.3873281\ttotal: 5m 8s\tremaining: 4m 56s\n",
      "255:\tlearn: 0.3871772\ttotal: 5m 9s\tremaining: 4m 55s\n",
      "256:\tlearn: 0.3869356\ttotal: 5m 10s\tremaining: 4m 53s\n",
      "257:\tlearn: 0.3862249\ttotal: 5m 11s\tremaining: 4m 52s\n",
      "258:\tlearn: 0.3858913\ttotal: 5m 12s\tremaining: 4m 51s\n",
      "259:\tlearn: 0.3854859\ttotal: 5m 13s\tremaining: 4m 49s\n",
      "260:\tlearn: 0.3851170\ttotal: 5m 14s\tremaining: 4m 48s\n",
      "261:\tlearn: 0.3848007\ttotal: 5m 15s\tremaining: 4m 46s\n",
      "262:\tlearn: 0.3844293\ttotal: 5m 16s\tremaining: 4m 45s\n",
      "263:\tlearn: 0.3840962\ttotal: 5m 18s\tremaining: 4m 44s\n",
      "264:\tlearn: 0.3839095\ttotal: 5m 19s\tremaining: 4m 43s\n",
      "265:\tlearn: 0.3837497\ttotal: 5m 20s\tremaining: 4m 41s\n",
      "266:\tlearn: 0.3835061\ttotal: 5m 21s\tremaining: 4m 40s\n",
      "267:\tlearn: 0.3828066\ttotal: 5m 22s\tremaining: 4m 39s\n",
      "268:\tlearn: 0.3825642\ttotal: 5m 23s\tremaining: 4m 38s\n",
      "269:\tlearn: 0.3824374\ttotal: 5m 24s\tremaining: 4m 36s\n",
      "270:\tlearn: 0.3822805\ttotal: 5m 25s\tremaining: 4m 35s\n",
      "271:\tlearn: 0.3820891\ttotal: 5m 27s\tremaining: 4m 34s\n",
      "272:\tlearn: 0.3817645\ttotal: 5m 28s\tremaining: 4m 32s\n",
      "273:\tlearn: 0.3813587\ttotal: 5m 29s\tremaining: 4m 31s\n",
      "274:\tlearn: 0.3804478\ttotal: 5m 30s\tremaining: 4m 30s\n",
      "275:\tlearn: 0.3802844\ttotal: 5m 31s\tremaining: 4m 28s\n",
      "276:\tlearn: 0.3801387\ttotal: 5m 32s\tremaining: 4m 27s\n",
      "277:\tlearn: 0.3799517\ttotal: 5m 33s\tremaining: 4m 26s\n",
      "278:\tlearn: 0.3793893\ttotal: 5m 35s\tremaining: 4m 25s\n",
      "279:\tlearn: 0.3791929\ttotal: 5m 36s\tremaining: 4m 24s\n",
      "280:\tlearn: 0.3790850\ttotal: 5m 37s\tremaining: 4m 23s\n",
      "281:\tlearn: 0.3788515\ttotal: 5m 38s\tremaining: 4m 21s\n",
      "282:\tlearn: 0.3787254\ttotal: 5m 39s\tremaining: 4m 20s\n",
      "283:\tlearn: 0.3786989\ttotal: 5m 39s\tremaining: 4m 18s\n",
      "284:\tlearn: 0.3785399\ttotal: 5m 41s\tremaining: 4m 17s\n",
      "285:\tlearn: 0.3781878\ttotal: 5m 42s\tremaining: 4m 16s\n",
      "286:\tlearn: 0.3779446\ttotal: 5m 43s\tremaining: 4m 14s\n",
      "287:\tlearn: 0.3777810\ttotal: 5m 44s\tremaining: 4m 13s\n",
      "288:\tlearn: 0.3776521\ttotal: 5m 45s\tremaining: 4m 12s\n",
      "289:\tlearn: 0.3774079\ttotal: 5m 46s\tremaining: 4m 10s\n",
      "290:\tlearn: 0.3769897\ttotal: 5m 47s\tremaining: 4m 9s\n",
      "291:\tlearn: 0.3766066\ttotal: 5m 48s\tremaining: 4m 8s\n",
      "292:\tlearn: 0.3762248\ttotal: 5m 50s\tremaining: 4m 7s\n",
      "293:\tlearn: 0.3760714\ttotal: 5m 51s\tremaining: 4m 6s\n",
      "294:\tlearn: 0.3758311\ttotal: 5m 53s\tremaining: 4m 5s\n",
      "295:\tlearn: 0.3756047\ttotal: 5m 55s\tremaining: 4m 4s\n",
      "296:\tlearn: 0.3753938\ttotal: 5m 57s\tremaining: 4m 4s\n",
      "297:\tlearn: 0.3750810\ttotal: 5m 58s\tremaining: 4m 3s\n",
      "298:\tlearn: 0.3747633\ttotal: 5m 59s\tremaining: 4m 1s\n",
      "299:\tlearn: 0.3744693\ttotal: 6m\tremaining: 4m\n",
      "300:\tlearn: 0.3743078\ttotal: 6m 1s\tremaining: 3m 59s\n",
      "301:\tlearn: 0.3740662\ttotal: 6m 2s\tremaining: 3m 57s\n",
      "302:\tlearn: 0.3736960\ttotal: 6m 3s\tremaining: 3m 56s\n",
      "303:\tlearn: 0.3733487\ttotal: 6m 4s\tremaining: 3m 55s\n",
      "304:\tlearn: 0.3732737\ttotal: 6m 6s\tremaining: 3m 54s\n",
      "305:\tlearn: 0.3729493\ttotal: 6m 7s\tremaining: 3m 52s\n",
      "306:\tlearn: 0.3725862\ttotal: 6m 8s\tremaining: 3m 51s\n",
      "307:\tlearn: 0.3723659\ttotal: 6m 9s\tremaining: 3m 50s\n",
      "308:\tlearn: 0.3718959\ttotal: 6m 10s\tremaining: 3m 49s\n",
      "309:\tlearn: 0.3715978\ttotal: 6m 11s\tremaining: 3m 47s\n",
      "310:\tlearn: 0.3712084\ttotal: 6m 12s\tremaining: 3m 46s\n",
      "311:\tlearn: 0.3709399\ttotal: 6m 13s\tremaining: 3m 45s\n",
      "312:\tlearn: 0.3708094\ttotal: 6m 14s\tremaining: 3m 43s\n",
      "313:\tlearn: 0.3705866\ttotal: 6m 15s\tremaining: 3m 42s\n",
      "314:\tlearn: 0.3702369\ttotal: 6m 16s\tremaining: 3m 40s\n",
      "315:\tlearn: 0.3698425\ttotal: 6m 17s\tremaining: 3m 39s\n",
      "316:\tlearn: 0.3695430\ttotal: 6m 18s\tremaining: 3m 38s\n",
      "317:\tlearn: 0.3693918\ttotal: 6m 19s\tremaining: 3m 36s\n",
      "318:\tlearn: 0.3690969\ttotal: 6m 20s\tremaining: 3m 35s\n",
      "319:\tlearn: 0.3687699\ttotal: 6m 21s\tremaining: 3m 34s\n",
      "320:\tlearn: 0.3685921\ttotal: 6m 22s\tremaining: 3m 33s\n",
      "321:\tlearn: 0.3683145\ttotal: 6m 23s\tremaining: 3m 32s\n",
      "322:\tlearn: 0.3681650\ttotal: 6m 24s\tremaining: 3m 30s\n",
      "323:\tlearn: 0.3680180\ttotal: 6m 26s\tremaining: 3m 29s\n",
      "324:\tlearn: 0.3677479\ttotal: 6m 27s\tremaining: 3m 28s\n",
      "325:\tlearn: 0.3675163\ttotal: 6m 28s\tremaining: 3m 27s\n",
      "326:\tlearn: 0.3673726\ttotal: 6m 29s\tremaining: 3m 25s\n",
      "327:\tlearn: 0.3672970\ttotal: 6m 30s\tremaining: 3m 24s\n",
      "328:\tlearn: 0.3670316\ttotal: 6m 31s\tremaining: 3m 23s\n",
      "329:\tlearn: 0.3669027\ttotal: 6m 32s\tremaining: 3m 22s\n",
      "330:\tlearn: 0.3667375\ttotal: 6m 33s\tremaining: 3m 20s\n",
      "331:\tlearn: 0.3665105\ttotal: 6m 34s\tremaining: 3m 19s\n",
      "332:\tlearn: 0.3664181\ttotal: 6m 36s\tremaining: 3m 19s\n",
      "333:\tlearn: 0.3662677\ttotal: 6m 38s\tremaining: 3m 18s\n",
      "334:\tlearn: 0.3662023\ttotal: 6m 40s\tremaining: 3m 17s\n",
      "335:\tlearn: 0.3661879\ttotal: 6m 40s\tremaining: 3m 15s\n",
      "336:\tlearn: 0.3657165\ttotal: 6m 41s\tremaining: 3m 14s\n",
      "337:\tlearn: 0.3654561\ttotal: 6m 44s\tremaining: 3m 13s\n",
      "338:\tlearn: 0.3652154\ttotal: 6m 46s\tremaining: 3m 12s\n",
      "339:\tlearn: 0.3650279\ttotal: 6m 47s\tremaining: 3m 11s\n",
      "340:\tlearn: 0.3648310\ttotal: 6m 49s\tremaining: 3m 10s\n",
      "341:\tlearn: 0.3645014\ttotal: 6m 51s\tremaining: 3m 10s\n",
      "342:\tlearn: 0.3642691\ttotal: 6m 53s\tremaining: 3m 9s\n",
      "343:\tlearn: 0.3639842\ttotal: 6m 54s\tremaining: 3m 8s\n",
      "344:\tlearn: 0.3637018\ttotal: 6m 56s\tremaining: 3m 7s\n",
      "345:\tlearn: 0.3630667\ttotal: 6m 58s\tremaining: 3m 6s\n",
      "346:\tlearn: 0.3624541\ttotal: 6m 59s\tremaining: 3m 5s\n",
      "347:\tlearn: 0.3623307\ttotal: 7m\tremaining: 3m 3s\n",
      "348:\tlearn: 0.3622076\ttotal: 7m 2s\tremaining: 3m 2s\n",
      "349:\tlearn: 0.3619745\ttotal: 7m 3s\tremaining: 3m 1s\n",
      "350:\tlearn: 0.3617782\ttotal: 7m 5s\tremaining: 3m\n",
      "351:\tlearn: 0.3615489\ttotal: 7m 6s\tremaining: 2m 59s\n",
      "352:\tlearn: 0.3613951\ttotal: 7m 7s\tremaining: 2m 57s\n",
      "353:\tlearn: 0.3611484\ttotal: 7m 8s\tremaining: 2m 56s\n",
      "354:\tlearn: 0.3607649\ttotal: 7m 9s\tremaining: 2m 55s\n",
      "355:\tlearn: 0.3606533\ttotal: 7m 10s\tremaining: 2m 54s\n",
      "356:\tlearn: 0.3604526\ttotal: 7m 12s\tremaining: 2m 53s\n",
      "357:\tlearn: 0.3602693\ttotal: 7m 13s\tremaining: 2m 51s\n",
      "358:\tlearn: 0.3601054\ttotal: 7m 14s\tremaining: 2m 50s\n",
      "359:\tlearn: 0.3597543\ttotal: 7m 16s\tremaining: 2m 49s\n",
      "360:\tlearn: 0.3595512\ttotal: 7m 17s\tremaining: 2m 48s\n",
      "361:\tlearn: 0.3590533\ttotal: 7m 18s\tremaining: 2m 47s\n",
      "362:\tlearn: 0.3587108\ttotal: 7m 19s\tremaining: 2m 45s\n",
      "363:\tlearn: 0.3585314\ttotal: 7m 20s\tremaining: 2m 44s\n",
      "364:\tlearn: 0.3583664\ttotal: 7m 21s\tremaining: 2m 43s\n",
      "365:\tlearn: 0.3580793\ttotal: 7m 22s\tremaining: 2m 41s\n",
      "366:\tlearn: 0.3579093\ttotal: 7m 23s\tremaining: 2m 40s\n",
      "367:\tlearn: 0.3577744\ttotal: 7m 24s\tremaining: 2m 39s\n",
      "368:\tlearn: 0.3574953\ttotal: 7m 25s\tremaining: 2m 38s\n",
      "369:\tlearn: 0.3573641\ttotal: 7m 26s\tremaining: 2m 36s\n",
      "370:\tlearn: 0.3571825\ttotal: 7m 28s\tremaining: 2m 35s\n",
      "371:\tlearn: 0.3570075\ttotal: 7m 29s\tremaining: 2m 34s\n",
      "372:\tlearn: 0.3568781\ttotal: 7m 30s\tremaining: 2m 33s\n",
      "373:\tlearn: 0.3566255\ttotal: 7m 31s\tremaining: 2m 32s\n",
      "374:\tlearn: 0.3564476\ttotal: 7m 32s\tremaining: 2m 30s\n",
      "375:\tlearn: 0.3560894\ttotal: 7m 33s\tremaining: 2m 29s\n",
      "376:\tlearn: 0.3559624\ttotal: 7m 34s\tremaining: 2m 28s\n",
      "377:\tlearn: 0.3557288\ttotal: 7m 35s\tremaining: 2m 27s\n",
      "378:\tlearn: 0.3555036\ttotal: 7m 36s\tremaining: 2m 25s\n",
      "379:\tlearn: 0.3553561\ttotal: 7m 37s\tremaining: 2m 24s\n",
      "380:\tlearn: 0.3550671\ttotal: 7m 38s\tremaining: 2m 23s\n",
      "381:\tlearn: 0.3549309\ttotal: 7m 39s\tremaining: 2m 22s\n",
      "382:\tlearn: 0.3548462\ttotal: 7m 40s\tremaining: 2m 20s\n",
      "383:\tlearn: 0.3546031\ttotal: 7m 42s\tremaining: 2m 19s\n",
      "384:\tlearn: 0.3544538\ttotal: 7m 43s\tremaining: 2m 18s\n",
      "385:\tlearn: 0.3539665\ttotal: 7m 44s\tremaining: 2m 17s\n",
      "386:\tlearn: 0.3538937\ttotal: 7m 45s\tremaining: 2m 15s\n",
      "387:\tlearn: 0.3536124\ttotal: 7m 46s\tremaining: 2m 14s\n",
      "388:\tlearn: 0.3533737\ttotal: 7m 47s\tremaining: 2m 13s\n",
      "389:\tlearn: 0.3529144\ttotal: 7m 48s\tremaining: 2m 12s\n",
      "390:\tlearn: 0.3527527\ttotal: 7m 49s\tremaining: 2m 10s\n",
      "391:\tlearn: 0.3526296\ttotal: 7m 50s\tremaining: 2m 9s\n",
      "392:\tlearn: 0.3525320\ttotal: 7m 51s\tremaining: 2m 8s\n",
      "393:\tlearn: 0.3523784\ttotal: 7m 52s\tremaining: 2m 7s\n",
      "394:\tlearn: 0.3522604\ttotal: 7m 53s\tremaining: 2m 5s\n",
      "395:\tlearn: 0.3519708\ttotal: 7m 54s\tremaining: 2m 4s\n",
      "396:\tlearn: 0.3517757\ttotal: 7m 55s\tremaining: 2m 3s\n",
      "397:\tlearn: 0.3515662\ttotal: 7m 57s\tremaining: 2m 2s\n",
      "398:\tlearn: 0.3515190\ttotal: 7m 58s\tremaining: 2m 1s\n",
      "399:\tlearn: 0.3514079\ttotal: 7m 59s\tremaining: 1m 59s\n",
      "400:\tlearn: 0.3513073\ttotal: 8m\tremaining: 1m 58s\n",
      "401:\tlearn: 0.3510668\ttotal: 8m 2s\tremaining: 1m 57s\n",
      "402:\tlearn: 0.3508668\ttotal: 8m 3s\tremaining: 1m 56s\n",
      "403:\tlearn: 0.3507823\ttotal: 8m 3s\tremaining: 1m 54s\n",
      "404:\tlearn: 0.3505155\ttotal: 8m 4s\tremaining: 1m 53s\n",
      "405:\tlearn: 0.3502774\ttotal: 8m 5s\tremaining: 1m 52s\n",
      "406:\tlearn: 0.3499946\ttotal: 8m 6s\tremaining: 1m 51s\n",
      "407:\tlearn: 0.3498163\ttotal: 8m 7s\tremaining: 1m 49s\n",
      "408:\tlearn: 0.3495753\ttotal: 8m 8s\tremaining: 1m 48s\n",
      "409:\tlearn: 0.3493556\ttotal: 8m 9s\tremaining: 1m 47s\n",
      "410:\tlearn: 0.3491649\ttotal: 8m 10s\tremaining: 1m 46s\n",
      "411:\tlearn: 0.3490873\ttotal: 8m 11s\tremaining: 1m 45s\n",
      "412:\tlearn: 0.3489602\ttotal: 8m 12s\tremaining: 1m 43s\n",
      "413:\tlearn: 0.3486428\ttotal: 8m 14s\tremaining: 1m 42s\n",
      "414:\tlearn: 0.3481958\ttotal: 8m 16s\tremaining: 1m 41s\n",
      "415:\tlearn: 0.3481504\ttotal: 8m 17s\tremaining: 1m 40s\n",
      "416:\tlearn: 0.3479029\ttotal: 8m 18s\tremaining: 1m 39s\n",
      "417:\tlearn: 0.3478399\ttotal: 8m 19s\tremaining: 1m 38s\n",
      "418:\tlearn: 0.3475009\ttotal: 8m 20s\tremaining: 1m 36s\n",
      "419:\tlearn: 0.3473403\ttotal: 8m 21s\tremaining: 1m 35s\n",
      "420:\tlearn: 0.3471469\ttotal: 8m 22s\tremaining: 1m 34s\n",
      "421:\tlearn: 0.3470043\ttotal: 8m 23s\tremaining: 1m 33s\n",
      "422:\tlearn: 0.3468374\ttotal: 8m 24s\tremaining: 1m 31s\n",
      "423:\tlearn: 0.3467566\ttotal: 8m 25s\tremaining: 1m 30s\n",
      "424:\tlearn: 0.3466704\ttotal: 8m 26s\tremaining: 1m 29s\n",
      "425:\tlearn: 0.3464083\ttotal: 8m 28s\tremaining: 1m 28s\n",
      "426:\tlearn: 0.3461797\ttotal: 8m 29s\tremaining: 1m 27s\n",
      "427:\tlearn: 0.3458098\ttotal: 8m 30s\tremaining: 1m 25s\n",
      "428:\tlearn: 0.3457085\ttotal: 8m 31s\tremaining: 1m 24s\n",
      "429:\tlearn: 0.3456273\ttotal: 8m 33s\tremaining: 1m 23s\n",
      "430:\tlearn: 0.3455610\ttotal: 8m 34s\tremaining: 1m 22s\n",
      "431:\tlearn: 0.3454175\ttotal: 8m 35s\tremaining: 1m 21s\n",
      "432:\tlearn: 0.3453560\ttotal: 8m 36s\tremaining: 1m 19s\n",
      "433:\tlearn: 0.3451882\ttotal: 8m 37s\tremaining: 1m 18s\n",
      "434:\tlearn: 0.3450761\ttotal: 8m 38s\tremaining: 1m 17s\n",
      "435:\tlearn: 0.3448135\ttotal: 8m 39s\tremaining: 1m 16s\n",
      "436:\tlearn: 0.3445095\ttotal: 8m 40s\tremaining: 1m 14s\n",
      "437:\tlearn: 0.3444189\ttotal: 8m 41s\tremaining: 1m 13s\n",
      "438:\tlearn: 0.3442823\ttotal: 8m 42s\tremaining: 1m 12s\n",
      "439:\tlearn: 0.3439009\ttotal: 8m 43s\tremaining: 1m 11s\n",
      "440:\tlearn: 0.3437860\ttotal: 8m 44s\tremaining: 1m 10s\n",
      "441:\tlearn: 0.3436361\ttotal: 8m 45s\tremaining: 1m 8s\n",
      "442:\tlearn: 0.3435632\ttotal: 8m 46s\tremaining: 1m 7s\n",
      "443:\tlearn: 0.3433316\ttotal: 8m 47s\tremaining: 1m 6s\n",
      "444:\tlearn: 0.3432045\ttotal: 8m 49s\tremaining: 1m 5s\n",
      "445:\tlearn: 0.3428756\ttotal: 8m 50s\tremaining: 1m 4s\n",
      "446:\tlearn: 0.3424537\ttotal: 8m 51s\tremaining: 1m 2s\n",
      "447:\tlearn: 0.3423272\ttotal: 8m 52s\tremaining: 1m 1s\n",
      "448:\tlearn: 0.3423129\ttotal: 8m 52s\tremaining: 1m\n",
      "449:\tlearn: 0.3420459\ttotal: 8m 53s\tremaining: 59.3s\n",
      "450:\tlearn: 0.3419212\ttotal: 8m 54s\tremaining: 58.1s\n",
      "451:\tlearn: 0.3416570\ttotal: 8m 55s\tremaining: 56.9s\n",
      "452:\tlearn: 0.3415605\ttotal: 8m 56s\tremaining: 55.7s\n",
      "453:\tlearn: 0.3413644\ttotal: 8m 57s\tremaining: 54.5s\n",
      "454:\tlearn: 0.3411797\ttotal: 8m 58s\tremaining: 53.3s\n",
      "455:\tlearn: 0.3410081\ttotal: 8m 59s\tremaining: 52.1s\n",
      "456:\tlearn: 0.3407687\ttotal: 9m\tremaining: 50.9s\n",
      "457:\tlearn: 0.3405641\ttotal: 9m 1s\tremaining: 49.7s\n",
      "458:\tlearn: 0.3404720\ttotal: 9m 3s\tremaining: 48.5s\n",
      "459:\tlearn: 0.3403901\ttotal: 9m 4s\tremaining: 47.3s\n",
      "460:\tlearn: 0.3403755\ttotal: 9m 5s\tremaining: 46.2s\n",
      "461:\tlearn: 0.3402164\ttotal: 9m 7s\tremaining: 45s\n",
      "462:\tlearn: 0.3401122\ttotal: 9m 8s\tremaining: 43.8s\n",
      "463:\tlearn: 0.3399918\ttotal: 9m 9s\tremaining: 42.6s\n",
      "464:\tlearn: 0.3398328\ttotal: 9m 10s\tremaining: 41.4s\n",
      "465:\tlearn: 0.3396565\ttotal: 9m 11s\tremaining: 40.2s\n",
      "466:\tlearn: 0.3396408\ttotal: 9m 11s\tremaining: 39s\n",
      "467:\tlearn: 0.3394972\ttotal: 9m 12s\tremaining: 37.8s\n",
      "468:\tlearn: 0.3391318\ttotal: 9m 13s\tremaining: 36.6s\n",
      "469:\tlearn: 0.3389538\ttotal: 9m 14s\tremaining: 35.4s\n",
      "470:\tlearn: 0.3388434\ttotal: 9m 15s\tremaining: 34.2s\n",
      "471:\tlearn: 0.3387301\ttotal: 9m 16s\tremaining: 33s\n",
      "472:\tlearn: 0.3385675\ttotal: 9m 17s\tremaining: 31.8s\n",
      "473:\tlearn: 0.3383011\ttotal: 9m 18s\tremaining: 30.7s\n",
      "474:\tlearn: 0.3379852\ttotal: 9m 20s\tremaining: 29.5s\n",
      "475:\tlearn: 0.3377515\ttotal: 9m 22s\tremaining: 28.3s\n",
      "476:\tlearn: 0.3376123\ttotal: 9m 23s\tremaining: 27.2s\n",
      "477:\tlearn: 0.3375092\ttotal: 9m 24s\tremaining: 26s\n",
      "478:\tlearn: 0.3374981\ttotal: 9m 24s\tremaining: 24.7s\n",
      "479:\tlearn: 0.3374014\ttotal: 9m 25s\tremaining: 23.6s\n",
      "480:\tlearn: 0.3373368\ttotal: 9m 26s\tremaining: 22.4s\n",
      "481:\tlearn: 0.3372985\ttotal: 9m 27s\tremaining: 21.2s\n",
      "482:\tlearn: 0.3372248\ttotal: 9m 28s\tremaining: 20s\n",
      "483:\tlearn: 0.3370401\ttotal: 9m 29s\tremaining: 18.8s\n",
      "484:\tlearn: 0.3367950\ttotal: 9m 30s\tremaining: 17.6s\n",
      "485:\tlearn: 0.3367290\ttotal: 9m 31s\tremaining: 16.5s\n",
      "486:\tlearn: 0.3364462\ttotal: 9m 32s\tremaining: 15.3s\n",
      "487:\tlearn: 0.3362712\ttotal: 9m 33s\tremaining: 14.1s\n",
      "488:\tlearn: 0.3359598\ttotal: 9m 34s\tremaining: 12.9s\n",
      "489:\tlearn: 0.3357776\ttotal: 9m 35s\tremaining: 11.8s\n",
      "490:\tlearn: 0.3355311\ttotal: 9m 37s\tremaining: 10.6s\n",
      "491:\tlearn: 0.3353232\ttotal: 9m 38s\tremaining: 9.41s\n",
      "492:\tlearn: 0.3350634\ttotal: 9m 39s\tremaining: 8.23s\n",
      "493:\tlearn: 0.3349397\ttotal: 9m 40s\tremaining: 7.05s\n",
      "494:\tlearn: 0.3348187\ttotal: 9m 41s\tremaining: 5.88s\n",
      "495:\tlearn: 0.3347209\ttotal: 9m 42s\tremaining: 4.7s\n",
      "496:\tlearn: 0.3346192\ttotal: 9m 43s\tremaining: 3.52s\n",
      "497:\tlearn: 0.3343100\ttotal: 9m 44s\tremaining: 2.35s\n",
      "498:\tlearn: 0.3341225\ttotal: 9m 45s\tremaining: 1.17s\n",
      "499:\tlearn: 0.3339813\ttotal: 9m 46s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2c894cb0fd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bestmodel 생성\n",
    "best_model = CatBoostClassifier(depth=10, iterations=500, l2_leaf_reg=3, learning_rate=0.05)\n",
    "best_model.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.895\n",
      "test score: 0.844\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = best_model.predict(X_train_final)\n",
    "train_accuracy = accuracy_score(y_train_final, y_train_hat)\n",
    "\n",
    "y_test_hat = best_model.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_hat)\n",
    "\n",
    "print(\"train score: %.3f\" %train_accuracy)\n",
    "print(\"test score: %.3f\" %test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       610\n",
      "           1       0.75      0.86      0.80       627\n",
      "           2       0.87      0.68      0.76       308\n",
      "           3       0.70      0.76      0.72       205\n",
      "           4       0.88      0.88      0.88      2426\n",
      "           5       0.97      0.97      0.97      1850\n",
      "           6       0.90      0.90      0.90       847\n",
      "           7       0.92      0.85      0.88       605\n",
      "\n",
      "    accuracy                           0.90      7478\n",
      "   macro avg       0.87      0.86      0.86      7478\n",
      "weighted avg       0.90      0.90      0.90      7478\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       143\n",
      "           1       0.69      0.77      0.73       157\n",
      "           2       0.71      0.61      0.66        77\n",
      "           3       0.65      0.75      0.70        57\n",
      "           4       0.80      0.81      0.81       596\n",
      "           5       0.95      0.94      0.95       470\n",
      "           6       0.89      0.84      0.86       198\n",
      "           7       0.90      0.80      0.85       172\n",
      "\n",
      "    accuracy                           0.84      1870\n",
      "   macro avg       0.81      0.81      0.81      1870\n",
      "weighted avg       0.85      0.84      0.84      1870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 최종 모델의 precsion, recall, f1-score\n",
    "print(classification_report(y_train_final, y_train_hat))\n",
    "print(classification_report(y_test, y_test_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**그러나 catBoost 모델의 경우 계산 비용이 너무커서 random forest 모델을 쓰는 것이 좋을 수도 있겠다.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
